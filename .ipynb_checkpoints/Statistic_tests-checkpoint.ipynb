{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c19b601-4fee-403b-9537-0415d244fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1a9b9a4-14f7-4a7c-b163-929ba14e64a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_datasheet = r'./results/behavioral/compare/compare.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b146ae86-9bbc-4d0e-a747-33891ed216a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_excel(config_datasheet)\n",
    "df = pd.DataFrame(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93ef41c4-53ce-444d-9266-567ac1651a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cliffs_delta(control, test):\n",
    "    \"\"\"\n",
    "    Computes Cliff's delta for 2 samples.\n",
    "    See https://en.wikipedia.org/wiki/Effect_size#Effect_size_for_ordinal_data\n",
    "\n",
    "    Keywords\n",
    "    --------\n",
    "    control, test: numeric iterables.\n",
    "        These can be lists, tuples, or arrays of numeric types.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        A single numeric float.\n",
    "    \"\"\"\n",
    "    #import numpy as np\n",
    "    #from scipy.stats import mannwhitneyu\n",
    "\n",
    "    # Convert to numpy arrays for speed.\n",
    "    # NaNs are automatically dropped.\n",
    "    if control.__class__ != np.ndarray:\n",
    "        control = np.array(control)\n",
    "    if test.__class__ != np.ndarray:\n",
    "        test    = np.array(test)\n",
    "\n",
    "    c = control[~np.isnan(control)]\n",
    "    t = test[~np.isnan(test)]\n",
    "\n",
    "    control_n = len(c)\n",
    "    test_n = len(t)\n",
    "\n",
    "    # Note the order of the control and test arrays.\n",
    "    U, _ = mannwhitneyu(t, c, alternative='two-sided')\n",
    "    cliffs_delta = ((2 * U) / (control_n * test_n)) - 1\n",
    "\n",
    "    # more = 0\n",
    "    # less = 0\n",
    "    #\n",
    "    # for i, c in enumerate(control):\n",
    "    #     for j, t in enumerate(test):\n",
    "    #         if t > c:\n",
    "    #             more += 1\n",
    "    #         elif t < c:\n",
    "    #             less += 1\n",
    "    #\n",
    "    # cliffs_delta = (more - less) / (control_n * test_n)\n",
    "\n",
    "    return cliffs_delta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6670247f-aa45-4ea5-9b63-074746a897d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-48-84dbb04abe03>, line 54)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-48-84dbb04abe03>\"\u001b[1;36m, line \u001b[1;32m54\u001b[0m\n\u001b[1;33m    tmp_post_correctness.mean()])#, wilcoxon(tmp_pre_correctness, tmp_post_correctness)['p-val'][0]])\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "\n",
    "from pingouin import mwu\n",
    "from pingouin import wilcoxon\n",
    "\n",
    "pre_list_same = [\"CommonChars-Pre\", \"ReverseArray-Pre\", \"BinarySearchStrings-Pre\", \"Multiples-Pre\", \"InsertionSort-Pre\"]\n",
    "post_list_same = [\"CommonChars-Post\", \"ReverseArray-Post\", \"BinarySearchStrings-Post\", \"Multiples-Post\", \"InsertionSort-Post\"]\n",
    "df[\"Correctness\"] = df[\"Correctness\"].astype(int)\n",
    "\n",
    "cliffs_delta_correctness = []\n",
    "cliffs_delta_response_time = []\n",
    "\n",
    "mwu_correctness = []\n",
    "mwu_response_time = []\n",
    "\n",
    "shapiro_pre_correctness = []\n",
    "shapiro_post_correctness = []\n",
    "shapiro_pre_response_time = []\n",
    "shapiro_post_response_time = []\n",
    "\n",
    "ttest_correctness = []\n",
    "ttest_response_time = []\n",
    "    \n",
    "wilcoxon_response_time = []\n",
    "wilcoxon_correctness = []\n",
    "\n",
    "for i in range(len(post_list_same)):\n",
    "    tmp_pre_response_time = df[df[\"Algorithm\"]==pre_list_same[i]][\"ResponseTime\"]\n",
    "    tmp_pre_correctness = df[df[\"Algorithm\"]==pre_list_same[i]][\"Correctness\"]\n",
    "    \n",
    "    tmp_post_response_time = df[df[\"Algorithm\"]==post_list_same[i]][\"ResponseTime\"]\n",
    "    tmp_post_correctness = df[df[\"Algorithm\"]==post_list_same[i]][\"Correctness\"]\n",
    "    \n",
    "    cliffs_delta_correctness.append([post_list_same[i][:-5], cliffs_delta(tmp_pre_correctness, tmp_post_correctness)])\n",
    "    cliffs_delta_response_time.append([post_list_same[i][:-5], cliffs_delta(tmp_pre_response_time, tmp_post_response_time)])\n",
    "\n",
    "    mwu_correctness.append([post_list_same[i][:-5], mwu(tmp_pre_correctness, tmp_post_correctness)])\n",
    "    mwu_response_time.append([post_list_same[i][:-5], mwu(tmp_pre_response_time, tmp_post_response_time)])\n",
    "    \n",
    "    shapiro_pre_correctness.append([post_list_same[i][:-5], stats.shapiro(tmp_pre_correctness)])\n",
    "    shapiro_post_correctness.append([post_list_same[i][:-5], stats.shapiro(tmp_post_correctness)])\n",
    "\n",
    "    shapiro_pre_response_time.append([post_list_same[i][:-5], stats.shapiro(tmp_pre_response_time)])\n",
    "    shapiro_post_response_time.append([post_list_same[i][:-5], stats.shapiro(tmp_post_response_time)])\n",
    "    \n",
    "    ttest_correctness.append([post_list_same[i][:-5], stats.ttest_rel(tmp_pre_correctness, tmp_post_correctness)])\n",
    "    ttest_response_time.append([post_list_same[i][:-5], stats.ttest_rel(tmp_pre_response_time, tmp_post_response_time)])\n",
    "\n",
    "    wilcoxon_correctness.append([post_list_same[i][:-5], wilcoxon(tmp_pre_correctness, tmp_post_correctness)])\n",
    "    wilcoxon_response_time.append([post_list_same[i][:-5], wilcoxon(tmp_pre_response_time, tmp_post_response_time)])\n",
    "        \n",
    "    #wilcoxon_correctness.append([post_list_same[i][:-5], tmp_pre_correctness.mean(), \n",
    "                                      #tmp_post_correctness.mean()])#, wilcoxon(tmp_pre_correctness, tmp_post_correctness)['p-val'][0]])\n",
    "    #wilcoxon_response_time.append([post_list_same[i][:-5], tmp_pre_response_time.mean(), \n",
    "                                        #tmp_post_response_time.mean(), wilcoxon(tmp_pre_response_time, tmp_post_response_time)['p-val'][0]])\n",
    "\n",
    "    #rint(stats.ttest_rel(tmp_pre_response_time, tmp_post_response_time))\n",
    "    #print(mwu(tmp_pre_correctness, tmp_post_correctness))\n",
    "\n",
    "import os \n",
    "\n",
    "#small, >= 0.11; medium, >= 0.28; large, >= 0.43\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "733809e9-9e77-4fd2-9274-66ed83e79715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithmus</th>\n",
       "      <th>Antwortzeit-Pre</th>\n",
       "      <th>Antwortzeit-Post</th>\n",
       "      <th>Wilcoxon-Ergebnis</th>\n",
       "      <th>Cliffs-Delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Algorithmus, Antwortzeit-Pre, Antwortzeit-Post, Wilcoxon-Ergebnis, Cliffs-Delta]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_statistic_correcntess = pd.DataFrame(columns=['Algorithmus', 'Korrektheit-Pre', 'Korrektheit-Post', 'Cliffs-Delta', 'MWU', 'Stats-Shapiro', 'Ttest', 'Wilcoxon'])\n",
    "df_statistic_response_time = pd.DataFrame(columns=['Algorithmus', 'Antwortzeit-Pre', 'Antwortzeit-Post', 'Cliffs-Delta', 'MWU', 'Stats-Shapiro', 'Ttest', 'Wilcoxon'])\n",
    "\n",
    "\n",
    "for i in range(len(wilcoxon_same_response_time)):\n",
    "    if wilcoxon_same_response_time[i][3] < 0.001: \n",
    "        df_wilcoxon_response_time = df_wilcoxon_response_time.append({'Algorithmus': wilcoxon_same_response_time[i][0], 'Antwortzeit-Pre': wilcoxon_same_response_time[i][1], \n",
    "                                          'Antwortzeit-Post': wilcoxon_same_response_time[i][2], 'Wilcoxon-Ergebnis': \"<0.001\", \n",
    "                                          'Cliffs-Delta': cliffs_delta_same[i]}, ignore_index=True)\n",
    "    else:    \n",
    "        df_wilcoxon_response_time = df_wilcoxon_response_time.append({'Algorithmus': wilcoxon_same_response_time[i][0], 'Antwortzeit-Pre': wilcoxon_same_response_time[i][1],\n",
    "                                                                      'Antwortzeit-Post': wilcoxon_same_response_time[i][2], 'Wilcoxon-Ergebnis': wilcoxon_same_response_time[i][3], \n",
    "                                                                      'Cliffs-Delta': cliffs_delta_same[i]}, ignore_index=True)\n",
    "    \n",
    "\n",
    "    \n",
    "with open('wilcoxon_same_response_time.tex', 'w') as tf:\n",
    "     tf.write(df_wilcoxon_response_time.to_latex(\n",
    "             index=False,\n",
    "             column_format=\"l|l|l|l\",\n",
    "             caption=\"Antwortzeiten\",\n",
    "             )\n",
    "            .replace('\\\\toprule', '\\\\hline').replace('\\\\midrule', '\\\\hline').replace('\\\\bottomrule','\\\\hline'))\n",
    "\n",
    "#display(metric_df)\n",
    "with open(\n",
    "    os.path.join(os.getcwd(),\"wilcoxon_same.tex\"), \"w\"\n",
    ") as tf:\n",
    "    tf.write(wilcoxon_df\n",
    "             .round(3)\n",
    "             .to_latex(\n",
    "                 index=False,\n",
    "                 label=\"tab:table_label\",\n",
    "                 escape=False,\n",
    "                 column_format=\"l|l|l|l\",\n",
    "                caption=\"This is the caption\",\n",
    "             )\n",
    "            .replace('\\\\toprule', '\\\\hline').replace('\\\\midrule', '\\\\hline').replace('\\\\bottomrule','\\\\hline'))\n",
    "\n",
    "    display(wilcoxon_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10884c0b-dde3-4e2a-a4fb-8bbe83433473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform mann whitney test\n",
    "#stat, p_value = mannwhitneyu(pre_common_chars_time, post_common_chars_time)\n",
    "#print('Statistics=%.2f, p=%f' % (stat, p_value))\n",
    "# Level of significance\n",
    "#alpha = 0.05\n",
    "# conclusion\n",
    "#if p_value < alpha:\n",
    "#    print('Reject Null Hypothesis (Significant difference between two samples)')\n",
    "#else:\n",
    "#    print('Do not Reject Null Hypothesis (No significant difference between two samples)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
