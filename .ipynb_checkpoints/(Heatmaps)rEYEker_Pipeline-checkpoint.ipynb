{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Data Analysis for REYeker</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lib for dataframes\n",
    "import pandas as pd\n",
    "\n",
    "# lib for saving np images\n",
    "from PIL import Image\n",
    "\n",
    "# lib for plotting\n",
    "#%matplotlib inline\n",
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# lib for numerical computations\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# lib for crerating paths\n",
    "from pathlib import Path\n",
    "\n",
    "# REYeker lib\n",
    "import modules.rEYEkerAnalysis as rEYEker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Configuration</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Database configuration </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the datafile\n",
    "config_datasheet_path_pre = r'./results/data_of_all_removed.xlsx'\n",
    "config_datasheet_path_post = r'./results/data_of_all_removed_posttest.xlsx'\n",
    "compare_datasheet = \"results/behavioral/compare/compare.xlsx\"\n",
    "\n",
    "# columns with visual stimulus data\n",
    "config_visual_stimulus_variable = \"ClickData\"\n",
    "\n",
    "# columns with names of the algo\n",
    "config_algo_name_variable = \"Algorithm\"\n",
    "\n",
    "# columns with correctness value\n",
    "config_corectness_variable = \"Correctness\"\n",
    "\n",
    "# colums of response time\n",
    "config_response_time_variable = \"ResponseTime\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Configuration for REYEker data </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file for loading rEYEker settings\n",
    "config_reyeker_settings_path = \"data/used.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Import the preprocessed dataframe</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n",
      "209\n",
      "176 33 209\n",
      "168 41 209\n"
     ]
    }
   ],
   "source": [
    "df_compare = pd.read_excel(compare_datasheet)\n",
    "\n",
    "df_pre_tmp = pd.read_excel(config_datasheet_path_pre)\n",
    "df_post_tmp = pd.read_excel(config_datasheet_path_post)\n",
    "\n",
    "\n",
    "df_pre= pd.DataFrame()\n",
    "df_post = pd.DataFrame()\n",
    "\n",
    "df_pre_correct = pd.DataFrame()\n",
    "df_post_correct = pd.DataFrame()\n",
    "\n",
    "df_pre_false = pd.DataFrame()\n",
    "df_post_false = pd.DataFrame()\n",
    "\n",
    "unique_codes = df_compare[\"Unique Code\"].unique()\n",
    "\n",
    "for code in unique_codes:\n",
    "    tmp_pre_correct = df_pre_tmp.loc[(df_pre_tmp[\"Unique Code\"] == code) & (df_pre_tmp[\"Correctness\"] == True)]\n",
    "    tmp_pre_false = df_pre_tmp.loc[(df_pre_tmp[\"Unique Code\"] == code) & (df_pre_tmp[\"Correctness\"] == False)]\n",
    "    tmp_pre = df_pre_tmp.loc[df_pre_tmp[\"Unique Code\"]== code]\n",
    "    \n",
    "    tmp_post_correct = df_post_tmp.loc[(df_post_tmp[\"Unique Code\"] == code) & (df_post_tmp[\"Correctness\"] == True)]\n",
    "    tmp_post_false = df_post_tmp.loc[(df_post_tmp[\"Unique Code\"] == code) & (df_post_tmp[\"Correctness\"] == False)]\n",
    "    tmp_post = df_post_tmp.loc[df_post_tmp[\"Unique Code\"]== code]\n",
    "    \n",
    "    df_pre_correct = df_pre_correct.append(tmp_pre_correct)\n",
    "    df_pre_false = df_pre_false.append(tmp_pre_false)\n",
    "    df_pre = df_pre.append(tmp_pre)\n",
    "\n",
    "    df_post_correct = df_post_correct.append(tmp_post_correct)\n",
    "    df_post_false = df_post_false.append(tmp_post_false)\n",
    "    df_post = df_post.append(tmp_post)\n",
    "\n",
    "print(len(df_pre))\n",
    "print(len(df_post))\n",
    "print(len(df_pre_correct), len(df_pre_false), len(df_pre))\n",
    "print(len(df_post_correct), len(df_post_false), len(df_post))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_name_array_pre = df_pre[\"Algorithm\"].unique()\n",
    "algo_name_array_post = df_post[\"Algorithm\"].unique()\n",
    "\n",
    "df_array_pre = []\n",
    "df_array_pre_false = []\n",
    "df_array_pre_correct = []\n",
    "\n",
    "df_array_post = []\n",
    "df_array_post_false = []\n",
    "df_array_post_correct = []\n",
    "\n",
    "for algo_name in algo_name_array_pre:\n",
    "    algo_df = df_pre.loc[df_pre[config_algo_name_variable]==algo_name]\n",
    "    algo_df_false = df_pre_false.loc[df_pre_false[config_algo_name_variable]==algo_name]\n",
    "    algo_df_correct = df_pre_correct.loc[df_pre_correct[config_algo_name_variable]==algo_name]\n",
    "    \n",
    "    \n",
    "    df_array_pre.append(algo_df)\n",
    "    df_array_pre_false.append(algo_df_false)\n",
    "    df_array_pre_correct.append(algo_df_correct)\n",
    "\n",
    "\n",
    "for algo_name in algo_name_array_post:\n",
    "    algo_df = df_post.loc[df_post[config_algo_name_variable]==algo_name]\n",
    "    algo_df_false = df_post_false.loc[df_post_false[config_algo_name_variable]==algo_name]\n",
    "    algo_df_correct = df_post_correct.loc[df_post_correct[config_algo_name_variable]==algo_name]\n",
    "    \n",
    "    df_array_post.append(algo_df)\n",
    "    df_array_post_false.append(algo_df_false)\n",
    "    df_array_post_correct.append(algo_df_correct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images/Posttest/CommonChars.png', 'images/Posttest/IsPalindrome.png', 'images/Posttest/ReverseString.png', 'images/Posttest/ReverseArray.png', 'images/Posttest/BinarySearchStrings.png', 'images/Posttest/Multiples.png', 'images/Posttest/Power.png', 'images/Posttest/GetMiddle.png', 'images/Posttest/InsertionSort.png', 'images/Posttest/SquareRoot.png']\n"
     ]
    }
   ],
   "source": [
    "# data for loading the images\n",
    "image_path_array_pre = []\n",
    "image_path_array_post = []\n",
    "\n",
    "for algo_name in algo_name_array_pre:\n",
    "    image_path = 'images/Pretest/' + algo_name + '.png'\n",
    "    image_path_array_pre.append(image_path)\n",
    "    \n",
    "for algo_name in algo_name_array_post:\n",
    "    image_path = 'images/Posttest/' + algo_name + '.png'\n",
    "    image_path_array_post.append(image_path)\n",
    "    \n",
    "print(image_path_array_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Import REYeker Settings</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_data, _times, click_setting) = rEYEker.load_data_from_json(config_reyeker_settings_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Import Images Settings</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array_pre = []\n",
    "image_array_post = []\n",
    "\n",
    "# read in every image\n",
    "for image_path in image_path_array_pre:\n",
    "    image = rEYEker.load_image(image_path)\n",
    "   \n",
    "    image_array_pre.append(image)\n",
    "    \n",
    "    \n",
    "for image_path in image_path_array_post:\n",
    "    image = rEYEker.load_image(image_path)\n",
    "    \n",
    "    image_array_post.append(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Cast Data to Valid format</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the visual stimulus measured Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "correct and false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_stimulus_data_matrix_pre = []\n",
    "\n",
    "for idx, dataframe in enumerate(df_array_pre):\n",
    "    visual_stimulus_array = []\n",
    "\n",
    "    #iter over every row \n",
    "    for _idx, row in dataframe.iterrows():\n",
    "        data_str = row[config_visual_stimulus_variable]\n",
    "        if isinstance(data_str, float)==True:\n",
    "            continue\n",
    "        data_str = data_str.strip()\n",
    "        \n",
    "        coordinates_str = data_str.split(\" \")\n",
    "        coordinates = []\n",
    "       \n",
    "        # iter over every coordinate pair x-y\n",
    "        for coordinate_str in coordinates_str:\n",
    "            try:\n",
    "                coordinate = coordinate_str.split(\"-\")\n",
    "                coordinate = (int(coordinate[0]), int(coordinate[1]))\n",
    "                coordinates.append(coordinate)\n",
    "            except:\n",
    "                print(coordinate_str)\n",
    "            \n",
    "        visual_stimulus_array.append(coordinates)\n",
    "        \n",
    "    visual_stimulus_data_matrix_pre.append(visual_stimulus_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_stimulus_data_matrix_post = []\n",
    "\n",
    "\n",
    "for idx, dataframe in enumerate(df_array_post):\n",
    "    visual_stimulus_array_post = []\n",
    "\n",
    "    #iter over every row \n",
    "    for _idx, row in dataframe.iterrows():\n",
    "        data_str_post = row[config_visual_stimulus_variable]\n",
    "        data_str_post = data_str_post.strip()\n",
    "        coordinates_str_post = data_str_post.split(\" \")\n",
    "        coordinates_post = []\n",
    "       \n",
    "        # iter over every coordinate pair x-y\n",
    "        for coordinate_str_post in coordinates_str_post:\n",
    "            try:\n",
    "                coordinate_post = coordinate_str_post.split(\"-\")\n",
    "                coordinate_post = (int(coordinate_post[0]), int(coordinate_post[1]))\n",
    "                coordinates_post.append(coordinate_post)\n",
    "            except:\n",
    "                print(coordinate_str_post)\n",
    "            \n",
    "            \n",
    "        visual_stimulus_array_post.append(coordinates_post)\n",
    "        \n",
    "    visual_stimulus_data_matrix_post.append(visual_stimulus_array_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_stimulus_data_matrix_pre_correct = []\n",
    "\n",
    "for idx, dataframe in enumerate(df_array_pre_correct):\n",
    "    visual_stimulus_array = []\n",
    "\n",
    "    #iter over every row \n",
    "    for _idx, row in dataframe.iterrows():\n",
    "        data_str = row[config_visual_stimulus_variable]\n",
    "        data_str = data_str.strip()\n",
    "        coordinates_str = data_str.split(\" \")\n",
    "        coordinates = []\n",
    "       \n",
    "        # iter over every coordinate pair x-y\n",
    "        for coordinate_str in coordinates_str:\n",
    "            try:\n",
    "                coordinate = coordinate_str.split(\"-\")\n",
    "                coordinate = (int(coordinate[0]), int(coordinate[1]))\n",
    "                coordinates.append(coordinate)\n",
    "            except:\n",
    "                print(coordinate_str)\n",
    "            \n",
    "            \n",
    "        visual_stimulus_array.append(coordinates)\n",
    "        \n",
    "    visual_stimulus_data_matrix_pre_correct.append(visual_stimulus_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_stimulus_data_matrix_post_correct = []\n",
    "\n",
    "for idx, dataframe in enumerate(df_array_post_correct):\n",
    "    visual_stimulus_array = []\n",
    "\n",
    "    #iter over every row \n",
    "    for _idx, row in dataframe.iterrows():\n",
    "        data_str = row[config_visual_stimulus_variable]\n",
    "        data_str = data_str.strip()\n",
    "        coordinates_str = data_str.split(\" \")\n",
    "        coordinates = []\n",
    "       \n",
    "        # iter over every coordinate pair x-y\n",
    "        for coordinate_str in coordinates_str:\n",
    "            try:\n",
    "                coordinate = coordinate_str.split(\"-\")\n",
    "                coordinate = (int(coordinate[0]), int(coordinate[1]))\n",
    "                coordinates.append(coordinate)\n",
    "            except:\n",
    "                print(coordinate_str)\n",
    "            \n",
    "            \n",
    "        visual_stimulus_array.append(coordinates)\n",
    "        \n",
    "    visual_stimulus_data_matrix_post_correct.append(visual_stimulus_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 6, 3, 23, 17, 22, 25, 30, 50, 12, 9, 19, 33, 19, 5, 4, 21, 8, 36, 8, 13]\n",
      "[6, 7, 10, 49, 3, 19, 10, 45, 7, 6, 4, 7, 30, 15, 4, 4, 10, 22, 9, 3, 11]\n",
      "[4, 53, 27, 62, 14, 33, 27, 125, 145, 36, 37, 11, 88, 40, 22, 16, 40, 31, 34, 28]\n",
      "[1, 6, 21, 12, 11, 6, 8, 31, 17, 19, 5, 8, 4, 10, 7, 1, 15, 5, 7, 9, 8]\n",
      "[2, 3, 20, 53, 6, 33, 25, 17, 57, 6, 23, 4, 47, 9, 37, 4, 16, 27, 22, 8, 23]\n",
      "\n",
      "[4, 10, 4, 11, 21, 15, 20, 19, 17, 11, 10, 9, 20, 6, 4, 5, 4, 9, 23, 7, 8]\n",
      "[2, 2, 16, 9, 11, 18, 6, 12, 26, 15, 8, 6, 11, 6, 2, 2, 4, 9, 16, 0, 4]\n",
      "[4, 17, 24, 2, 16, 45, 47, 57, 38, 33, 28, 10, 65, 62, 19, 21, 28, 13, 5, 18]\n",
      "[2, 11, 11, 6, 12, 3, 6, 19, 4, 14, 8, 10, 12, 15, 7, 2, 17, 3, 6, 5, 6]\n",
      "[3, 10, 8, 9, 6, 19, 23, 30, 60, 1, 6, 12, 60, 9, 20, 12, 22, 10, 5, 0, 26]\n"
     ]
    }
   ],
   "source": [
    "common_chars_stimulus_pre = visual_stimulus_data_matrix_pre[0]\n",
    "common_chars_stimulus_post = visual_stimulus_data_matrix_post[0]\n",
    "\n",
    "reverse_array_stimulus_pre = visual_stimulus_data_matrix_pre[3]\n",
    "reverse_array_stimulus_post = visual_stimulus_data_matrix_post[3]\n",
    "\n",
    "binary_search_stimulus_pre = visual_stimulus_data_matrix_pre[4]\n",
    "binary_search_stimulus_post = visual_stimulus_data_matrix_post[4]\n",
    "\n",
    "multiples_stimulus_pre = visual_stimulus_data_matrix_pre[5]\n",
    "multiples_stimulus_post = visual_stimulus_data_matrix_post[5]\n",
    "\n",
    "insertion_sort_stimulus_pre = visual_stimulus_data_matrix_pre[8]\n",
    "insertion_sort_stimulus_post = visual_stimulus_data_matrix_post[8]\n",
    "\n",
    "\n",
    "#0, 3, 4, 5, 8\n",
    "\n",
    "wilcoxon_fixation_count_same = []\n",
    "\n",
    "import scipy.stats as stats \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fixation_count_pre = [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
    "\n",
    "fixation_count_post = [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
    "\n",
    "for i in range(len(common_chars_stimulus_pre)):\n",
    "    for x, y in common_chars_stimulus_pre[i]:\n",
    "        if (x >= 45 and x <= 385) and ((y >= 169 and y <= 228) or (y >= 274 and y <= 348)):\n",
    "            fixation_count_pre[0][i] += 1\n",
    "            \n",
    "for i in range(len(common_chars_stimulus_post)):\n",
    "    for x, y in common_chars_stimulus_post[i]:\n",
    "        #if (x >= 50 and x <= 136) and (y >= 169 and y <= 213):\n",
    "        if (x >= 45 and x <= 391) and ((y >= 184 and y <= 243) or (y >= 288 and y <= 363)):\n",
    "            fixation_count_post[0][i] += 1\n",
    "            \n",
    "for i in range(len(reverse_array_stimulus_pre)):\n",
    "    for x, y in reverse_array_stimulus_pre[i]:\n",
    "        if x >= 45 and (y >= 229 and y <= 303):\n",
    "            fixation_count_pre[1][i] += 1\n",
    "            \n",
    "for i in range(len(reverse_array_stimulus_post)):\n",
    "    for x, y in reverse_array_stimulus_post[i]:\n",
    "        if x >= 45 and (y >= 205 and y <= 285):\n",
    "            fixation_count_post[1][i] += 1\n",
    "            \n",
    "for i in range(len(binary_search_stimulus_pre)):\n",
    "    for x, y in binary_search_stimulus_pre[i]:\n",
    "        if (x >= 40 and x <= 371) and ((y >= 169 and y <= 288) or (y >= 304 and y <= 408)):\n",
    "            fixation_count_pre[2][i] += 1\n",
    "            \n",
    "for i in range(len(binary_search_stimulus_post)):\n",
    "    for x, y in binary_search_stimulus_post[i]:\n",
    "        if (x >= 40 and x <= 369) and ((y >= 169 and y <= 288) or (y >= 304 and y <= 408)):\n",
    "            fixation_count_post[2][i] += 1\n",
    "\n",
    "for i in range(len(multiples_stimulus_pre)):\n",
    "    for x, y in multiples_stimulus_pre[i]:\n",
    "        if (x >= 45 and x <= 315) and (y >= 152 and y <= 234):\n",
    "            fixation_count_pre[3][i] += 1\n",
    "            \n",
    "for i in range(len(multiples_stimulus_post)):\n",
    "    for x, y in multiples_stimulus_post[i]:\n",
    "        #if (x >= 50 and x <= 136) and (y >= 169 and y <= 213):\n",
    "        if (x >= 45 and x <= 315) and (y >= 152 and y <= 234):\n",
    "            fixation_count_post[3][i] += 1\n",
    "            \n",
    "            \n",
    "for i in range(len(insertion_sort_stimulus_pre)):\n",
    "    for x, y in insertion_sort_stimulus_pre[i]:\n",
    "        if x >= 40 and (y >= 226 and y <= 360):\n",
    "            fixation_count_pre[4][i] += 1\n",
    "            \n",
    "for i in range(len(insertion_sort_stimulus_post)):\n",
    "    for x, y in insertion_sort_stimulus_post[i]:\n",
    "        if x >= 40 and (y >= 226 and y <= 360):\n",
    "            fixation_count_post[4][i] += 1\n",
    "            \n",
    "            \n",
    "for f in fixation_count_pre:\n",
    "    print(f)\n",
    "\n",
    "print()\n",
    "for f in fixation_count_post:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.03846153846154 14.461538461538462\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Programmverständnisaufgaben</th>\n",
       "      <th>Klickanzahl Pretest</th>\n",
       "      <th>Klickanzahl Posttest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V1</td>\n",
       "      <td>18.142857</td>\n",
       "      <td>11.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V2</td>\n",
       "      <td>13.380952</td>\n",
       "      <td>8.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V3</td>\n",
       "      <td>43.650000</td>\n",
       "      <td>27.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V4</td>\n",
       "      <td>10.047619</td>\n",
       "      <td>8.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V5</td>\n",
       "      <td>21.047619</td>\n",
       "      <td>16.714286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Programmverständnisaufgaben  Klickanzahl Pretest  Klickanzahl Posttest\n",
       "0                          V1            18.142857             11.285714\n",
       "0                          V2            13.380952              8.809524\n",
       "0                          V3            43.650000             27.600000\n",
       "0                          V4            10.047619              8.523810\n",
       "0                          V5            21.047619             16.714286"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar_df = pd.DataFrame([],columns=[\"Programmverständnisaufgaben\",\"Klickanzahl Pretest\", \"Klickanzahl Posttest\"])\n",
    "\n",
    "\n",
    "pre_total = 0\n",
    "post_total = 0\n",
    "\n",
    "for i in range(5):\n",
    "    tmp_pre = 0\n",
    "    tmp_post = 0\n",
    "    \n",
    "   \n",
    "    for fixation in fixation_count_pre[i]:\n",
    "        pre_total += fixation\n",
    "        tmp_pre += fixation\n",
    "    for fixation in fixation_count_post[i]:\n",
    "        post_total += fixation\n",
    "        tmp_post += fixation\n",
    "        \n",
    "    count = 21\n",
    "    if i == 2:\n",
    "        count = 20\n",
    "    else:\n",
    "        count = 21\n",
    "    bar_df = bar_df.append(pd.DataFrame([[\"V\" + str(i+1), tmp_pre/count, tmp_post/count]], \n",
    "                            columns=[\"Programmverständnisaufgaben\", \"Klickanzahl Pretest\", \"Klickanzahl Posttest\"]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(pre_total/104, post_total/104)\n",
    "\n",
    "display(bar_df)\n",
    "\n",
    "\n",
    "bar_df = bar_df.append(pd.DataFrame([[\"Insgesamt\", pre_total/104, post_total/104]], columns=[\"Programmverständnisaufgaben\", \"Klickanzahl Pretest\", \"Klickanzahl Posttest\"]))\n",
    "   \n",
    "bar_df = bar_df.set_index('Programmverständnisaufgaben')\n",
    "ax = bar_df.plot.bar(ylabel='Klickanzahl (AOI)', rot=0)\n",
    "plt.tight_layout()\n",
    "ax.legend(loc=\"center left\", bbox_to_anchor=(1.0, 0.5))\n",
    "plt.savefig(\"results/behavioral/v_klickanzahl.pdf\", bbox_inches='tight', pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Klickanzahl (AOI)</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>Pretest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>Pretest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Pretest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>Pretest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>Pretest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>22</td>\n",
       "      <td>Posttest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>10</td>\n",
       "      <td>Posttest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5</td>\n",
       "      <td>Posttest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0</td>\n",
       "      <td>Posttest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>26</td>\n",
       "      <td>Posttest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Klickanzahl (AOI)      Test\n",
       "0                   18   Pretest\n",
       "1                    6   Pretest\n",
       "2                    3   Pretest\n",
       "3                   23   Pretest\n",
       "4                   17   Pretest\n",
       "..                 ...       ...\n",
       "99                  22  Posttest\n",
       "100                 10  Posttest\n",
       "101                  5  Posttest\n",
       "102                  0  Posttest\n",
       "103                 26  Posttest\n",
       "\n",
       "[208 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flat_list_pre = [item for sublist in fixation_count_pre for item in sublist]\n",
    "flat_list_post = [item for sublist in fixation_count_post for item in sublist]\n",
    "\n",
    "pre_box = pd.DataFrame(flat_list_pre, columns=[\"Klickanzahl (AOI)\"])\n",
    "pre_box[\"Test\"] = \"Pretest\"\n",
    "\n",
    "\n",
    "post_box = pd.DataFrame(flat_list_post, columns=[\"Klickanzahl (AOI)\"])\n",
    "post_box[\"Test\"] = \"Posttest\"\n",
    "\n",
    "zusammen = [pre_box, post_box]\n",
    "\n",
    "aoi_plot = pd.concat(zusammen)\n",
    "\n",
    "display(aoi_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=\"Test\", y=\"Klickanzahl (AOI)\", data=aoi_plot)\n",
    "\n",
    "ax.set_xlabel(\"\");\n",
    "\n",
    "\n",
    "ax.set_xticklabels(ax.get_xticklabels())\n",
    "plt.ylim(0, 160)\n",
    "\n",
    "plt.savefig(\"results/behavioral/v_klickanzahl_boxplot.pdf\", bbox_inches='tight', pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "104\n",
      "           W-val alternative     p-val       RBC      CLES\n",
      "Wilcoxon  1420.0   two-sided  0.000144  0.437624  0.594397\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Verständnisaufgaben</th>\n",
       "      <th>Pretest</th>\n",
       "      <th>Posttest</th>\n",
       "      <th>Wilcoxon</th>\n",
       "      <th>Cliffs-Delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V1 - V5</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Verständnisaufgaben Pretest Posttest  Wilcoxon  Cliffs-Delta\n",
       "0             V1 - V5      21       14       0.0          0.19"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "fixation_count_pre_list = [item for sublist in fixation_count_pre for item in sublist]\n",
    "fixation_count_post_list = [item for sublist in fixation_count_post for item in sublist]\n",
    "\n",
    "\n",
    "print(len(fixation_count_pre_list))\n",
    "print(len(fixation_count_post_list))\n",
    "\n",
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "  \n",
    "average_pre = Average(fixation_count_pre_list)\n",
    "average_post = Average(fixation_count_post_list)\n",
    "\n",
    "from cliffs_delta import cliffs_delta\n",
    "from pingouin import wilcoxon\n",
    "wilco = wilcoxon(fixation_count_pre_list, fixation_count_post_list)\n",
    "cliff = cliffs_delta(fixation_count_pre_list, fixation_count_post_list)\n",
    "\n",
    "print(wilco)\n",
    "\n",
    "\n",
    "#round(wilcoxon_fixation_count_same[i][\"p-val\"][0], 5)\n",
    "#round(cliffs_delta_fixation_count_same[i][0], 5)\n",
    "\n",
    "df_fixation_count_same = pd.DataFrame([],\n",
    "                                        columns=['Verständnisaufgaben', 'Pretest', 'Posttest', 'Wilcoxon', 'Cliffs-Delta'])\n",
    "df_fixation_count_same = df_fixation_count_same.append({'Verständnisaufgaben': \"V1 - V5\",\n",
    "                                                                            'Pretest': int(round(average_pre)),\n",
    "                                                                            'Posttest': int(round(average_post)),\n",
    "                                                                            'Wilcoxon': round(wilco[\"p-val\"][0], 2),\n",
    "                                                                            'Cliffs-Delta': round(cliff[0], 2)}, ignore_index=True)\n",
    "\n",
    "display(df_fixation_count_same)\n",
    "import os \n",
    "\n",
    "with open(os.path.join(os.getcwd(),\"klickanzahl.tex\"), \"w\"\n",
    ") as tf:\n",
    "    tf.write(df_fixation_count_same\n",
    "             .to_latex(\n",
    "             \n",
    "             index=False,\n",
    "             caption=\"Verständnisaufgaben: Durchschnittliche Klickanzahl\",\n",
    "                 escape=False,\n",
    "                 column_format=\"ccccc\",\n",
    "             ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-46da8ba04517>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;31m#if (x >= 50 and x <= 136) and (y >= 169 and y <= 213):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m45\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m391\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m184\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m243\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m288\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m363\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[0mfixation_count_post\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mstimulus_pre\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreverse_array_stimulus_pre\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "from cliffs_delta import cliffs_delta\n",
    "from pingouin import wilcoxon\n",
    "\n",
    "\n",
    "#fixation_count_df = pd.DataFrame([], columns=[\"V1-pre\", \"V1-post\",\n",
    "#                                              \"V2-pre\", \"V2-post\",\n",
    "#                                              \"V3-pre\", \"V3-post\",\n",
    "#                                              \"V4-pre\", \"V4-post\",\n",
    "#                                              \"V5-pre\", \"V5-post\"])\n",
    "#\n",
    "#\n",
    "#\n",
    "#print(fixation_count_pre, fixation_count_post)\n",
    "#\n",
    "#for i in range(len(visual_stimulus_data_matrix_pre)):\n",
    "#    if i == 0:\n",
    "#        for i in range(len(visual_stimulus_data_matrix_pre[0])):\n",
    "#            fixation_count_df.at[i, \"V1-pre\"] = len(visual_stimulus_data_matrix_pre[0][i])\n",
    "#        for i in range(len(visual_stimulus_data_matrix_post[0])):\n",
    "#            fixation_count_df.at[i, \"V1-post\"] = len(visual_stimulus_data_matrix_post[0][i])\n",
    "#            \n",
    "#    if i == 3:\n",
    "#        for i in range(len(visual_stimulus_data_matrix_pre[3])):\n",
    "#            fixation_count_df.at[i, \"V2-pre\"] = len(visual_stimulus_data_matrix_pre[3][i])\n",
    "#        for i in range(len(visual_stimulus_data_matrix_post[3])):\n",
    "#            fixation_count_df.at[i, \"V2-post\"] = len(visual_stimulus_data_matrix_post[3][i])\n",
    "#            \n",
    "#            \n",
    "#    if i == 4:\n",
    "#        for i in range(len(visual_stimulus_data_matrix_pre[4])):\n",
    "#            fixation_count_df.at[i, \"V3-pre\"] = len(visual_stimulus_data_matrix_pre[4][i])\n",
    "#        for i in range(len(visual_stimulus_data_matrix_post[4])):\n",
    "#            fixation_count_df.at[i, \"V3-post\"] = len(visual_stimulus_data_matrix_post[4][i])\n",
    "#            \n",
    "#    if i == 5:\n",
    "#        for i in range(len(visual_stimulus_data_matrix_pre[5])):\n",
    "#            fixation_count_df.at[i, \"V4-pre\"] = len(visual_stimulus_data_matrix_pre[5][i])\n",
    "#        for i in range(len(visual_stimulus_data_matrix_post[5])):\n",
    "#            fixation_count_df.at[i, \"V4-post\"] = len(visual_stimulus_data_matrix_post[5][i])\n",
    "#            \n",
    "#    if i == 8:\n",
    "#        for i in range(len(visual_stimulus_data_matrix_pre[8])):\n",
    "#            fixation_count_df.at[i, \"V5-pre\"] = len(visual_stimulus_data_matrix_pre[8][i])\n",
    "#        for i in range(len(visual_stimulus_data_matrix_post[8])):\n",
    "#            fixation_count_df.at[i, \"V5-post\"] = len(visual_stimulus_data_matrix_post[8][i])\n",
    "#\n",
    "#\n",
    "#df_fixation_count_same = pd.DataFrame([],\n",
    "#                                        columns=['Verständnisaufgabe', 'Pretest', 'Posttest', 'Wilcoxon', 'Cliffs-Delta'])\n",
    "#\n",
    "#wilcoxon_fixation_count_same = []\n",
    "#cliffs_delta_fixation_count_same = []\n",
    "#\n",
    "##tmp = wilcoxon(fixation_count_df[\"V1-pre\"], fixation_count_df[\"V1-post\"])\n",
    "#\n",
    "#display(fixation_count_df)\n",
    "#\n",
    "#names = ['V1-pre', 'V1-post',\n",
    "#        'V2-pre', 'V2-post',\n",
    "#        'V3-pre', 'V3-post',\n",
    "#        'V4-pre', 'V4-post',\n",
    "#        'V5-pre', 'V5-post']\n",
    "#\n",
    "#\n",
    "#for name in names:\n",
    "#    fixation_count_df[name] = pd.to_numeric(fixation_count_df[name])\n",
    "#    \n",
    "#wilcoxon_fixation_count_same.append(wilcoxon(fixation_count_df[names[0]], fixation_count_df[names[1]]))\n",
    "#wilcoxon_fixation_count_same.append(wilcoxon(fixation_count_df[names[2]], fixation_count_df[names[3]]))\n",
    "#wilcoxon_fixation_count_same.append(wilcoxon(fixation_count_df[names[4]], fixation_count_df[names[5]]))\n",
    "#wilcoxon_fixation_count_same.append(wilcoxon(fixation_count_df[names[6]], fixation_count_df[names[7]]))\n",
    "#wilcoxon_fixation_count_same.append(wilcoxon(fixation_count_df[names[8]], fixation_count_df[names[9]]))\n",
    "#\n",
    "#    \n",
    "#cliffs_delta_fixation_count_same.append(cliffs_delta(fixation_count_df[names[0]], fixation_count_df[names[1]]))\n",
    "#cliffs_delta_fixation_count_same.append(cliffs_delta(fixation_count_df[names[2]], fixation_count_df[names[3]]))\n",
    "#cliffs_delta_fixation_count_same.append(cliffs_delta(fixation_count_df[names[4]], fixation_count_df[names[5]]))\n",
    "#cliffs_delta_fixation_count_same.append(cliffs_delta(fixation_count_df[names[6]], fixation_count_df[names[7]]))\n",
    "#cliffs_delta_fixation_count_same.append(cliffs_delta(fixation_count_df[names[8]], fixation_count_df[names[9]]))\n",
    "#\n",
    "#print(cliffs_delta_fixation_count_same[0][0])\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#print(round(wilcoxon_fixation_count_same[0][\"p-val\"][0], 5))\n",
    "#print(len(fixation_count_df))\n",
    "#for i in range(5):\n",
    "#    tmp_str = \"V\" + str(i+1)\n",
    "#    df_fixation_count_same = df_fixation_count_same.append({'Verständnisaufgabe': \"V\" + str(i+1),\n",
    "#                                                                            'Pretest': int(round(fixation_count_df[tmp_str+\"-pre\"].mean())),\n",
    "#                                                                            'Posttest': int(round(fixation_count_df[tmp_str+\"-post\"].mean())),\n",
    "#                                                                            'Wilcoxon': round(wilcoxon_fixation_count_same[i][\"p-val\"][0], 5),\n",
    "#                                                                            'Cliffs-Delta': round(cliffs_delta_fixation_count_same[i][0], 5)}, ignore_index=True)\n",
    "##import os \n",
    "#\n",
    "\n",
    "#with open(os.path.join(os.getcwd(),\"same_algorithm_fixation_count.tex\"), \"w\"\n",
    "#) as tf:\n",
    "#    tf.write(df_fixation_count_same\n",
    "#             .to_latex(\n",
    "#             \n",
    "#             index=False,\n",
    "#             caption=\"Verständnisaufgaben: Durchschnittliche Klickanzahl\",\n",
    "#                 escape=False,\n",
    "#                 column_format=\"ccccc\",\n",
    "#             ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_fixation_count_same)\n",
    "\n",
    "bar_df = pd.DataFrame([],columns=[\"Verständnisaufgaben\",\"Klickanzahl Pretest\", \"Klickanzahl Posttest\"])\n",
    "\n",
    "\n",
    "pre_total = 0\n",
    "post_total = 0\n",
    "\n",
    "for i in range(5):\n",
    "    bar_df = bar_df.append(pd.DataFrame([[df_fixation_count_same.iloc[i][0], df_fixation_count_same.iloc[i][1], df_fixation_count_same.iloc[i][2]]], \n",
    "                                    columns=[\"Verständnisaufgaben\", \"Klickanzahl Pretest\", \"Klickanzahl Posttest\"]))\n",
    "    pre_total += df_fixation_count_same.iloc[i][1]\n",
    "    post_total += df_fixation_count_same.iloc[i][2]\n",
    "\n",
    "pre_total /= 5\n",
    "post_total /= 5\n",
    "\n",
    "print(pre_total, post_total)\n",
    "\n",
    "bar_df = bar_df.append(pd.DataFrame([[\"Insgesamt\", pre_total, post_total]], columns=[\"Verständnisaufgaben\", \"Klickanzahl Pretest\", \"Klickanzahl Posttest\"]))\n",
    "    \n",
    "bar_df = bar_df.set_index('Verständnisaufgaben')\n",
    "ax = bar_df.plot.bar(ylabel='Klickanzahl (AOIs)', rot=0)\n",
    "plt.tight_layout()\n",
    "ax.legend(loc=\"center left\", bbox_to_anchor=(1.0, 0.5))\n",
    "plt.savefig(\"results/behavioral/tmp.pdf\", bbox_inches='tight', pad_inches=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sonaion_analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sonaion_analysis.utils.smallestenclosingcircle import make_circle\n",
    "\n",
    "\n",
    "def create_fixxation_map(eye_x, eye_y, fixxation_classifier):\n",
    "    points_array = []\n",
    "    currently_fixxation = False\n",
    "    current_points = []\n",
    "\n",
    "    for idx, classifier in enumerate(fixxation_classifier):\n",
    "        #if classifier == 1 and currently_fixxation == False:\n",
    "        #    current_points = [(eye_x[idx], eye_y[idx])]\n",
    "        #    currently_fixxation = True\n",
    "        if classifier == 1:\n",
    "            current_points.append((eye_x[idx], eye_y[idx]))\n",
    "            points_array.append((current_points, True))\n",
    "            current_points = []\n",
    "        \n",
    "        \n",
    "        #elif classifier == 0 and currently_fixxation == True:\n",
    "        #    points_array.append((current_points.copy(), True))\n",
    "        #    current_points = []\n",
    "        #    currently_fixxation = False\n",
    "        #    points_array.append(([(eye_x[idx], eye_y[idx])], False))\n",
    "        #else:\n",
    "        #    points_array.append(([(eye_x[idx], eye_y[idx])], False))\n",
    "    #circles = []\n",
    "    #circle1 = plt.Circle((0, 0), 0.2, color='r')\n",
    "    \n",
    "    #for points, is_fixxation in points_array:\n",
    "        #print(points, is_fixxation)\n",
    "        #print(points[0][0])\n",
    "        #circles.append(plt.Circle((points[0][0], points[0][1]), 30, color='r'))\n",
    "    \n",
    "    circles = [(make_circle(points), is_fixxation) for points, is_fixxation in points_array]\n",
    "    circles = [((x, y), 30, is_fixxation) for ((x, y, radius), is_fixxation) in circles]\n",
    "    \n",
    "    return circles\n",
    "\n",
    "\n",
    "def interpolate(start_color, end_color, current, max_value):\n",
    "    t = current / float(max_value)\n",
    "    r = (1.0 - t) * start_color[0] + t * end_color[0]\n",
    "    g = (1.0 - t) * start_color[1] + t * end_color[1]\n",
    "    b = (1.0 - t) * start_color[2] + t * end_color[2]\n",
    "    return (r, g, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_coordinates = []\n",
    "y_coordinates = []\n",
    "\n",
    "for x,y in visual_stimulus_data_matrix_post[1][5]:\n",
    "    x_coordinates.append(x)\n",
    "    y_coordinates.append(y)\n",
    "    \n",
    "fixations = [1] * len(x_coordinates)\n",
    "\n",
    "img = image_array_post[1]\n",
    "fixxation_map = create_fixxation_map(x_coordinates, y_coordinates, fixations)\n",
    "\n",
    "left_color = (1.0, 0.0, 0.0)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x_val = [float(int(x)) for ((x, _), _, _) in fixxation_map]\n",
    "y_val = [float(int(y)) for ((_, y), _, _) in fixxation_map]\n",
    "\n",
    "for i in range(len(x_val) - 2):\n",
    "    ax.plot(x_val[i : i + 2], y_val[i : i + 2], \"-\", color=interpolate(left_color, (0.0, 0.0, 0.0), i, len(x_val)), zorder=2, alpha=0.6)\n",
    "\n",
    "filtered_x_val = [float(int(x)) for ((x, _), _, flag) in fixxation_map if flag]\n",
    "filtered_y_val = [float(int(y)) for ((_, y), _, flag) in fixxation_map if flag]\n",
    "ax.scatter(filtered_x_val, filtered_y_val, 30, c=[interpolate(left_color, (0.0, 0.0, 0.0), idx, len(x_val)) for idx, (_, _, flag) in enumerate(fixxation_map) if flag], zorder=3, alpha=0.6)\n",
    "ax.imshow(img, zorder=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_stimulus_data_matrix_pre_false = []\n",
    "\n",
    "for idx, dataframe in enumerate(df_array_pre_false):\n",
    "    visual_stimulus_array = []\n",
    "\n",
    "    #iter over every row \n",
    "    for _idx, row in dataframe.iterrows():\n",
    "        data_str = row[config_visual_stimulus_variable]\n",
    "        data_str = data_str.strip()\n",
    "        coordinates_str = data_str.split(\" \")\n",
    "        coordinates = []\n",
    "       \n",
    "        # iter over every coordinate pair x-y\n",
    "        for coordinate_str in coordinates_str:\n",
    "            try:\n",
    "                coordinate = coordinate_str.split(\"-\")\n",
    "                coordinate = (int(coordinate[0]), int(coordinate[1]))\n",
    "                coordinates.append(coordinate)\n",
    "            except:\n",
    "                print(coordinate_str)\n",
    "            \n",
    "            \n",
    "        visual_stimulus_array.append(coordinates)\n",
    "        \n",
    "    visual_stimulus_data_matrix_pre_false.append(visual_stimulus_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_stimulus_data_matrix_post_false = []\n",
    "\n",
    "for idx, dataframe in enumerate(df_array_post_false):\n",
    "    visual_stimulus_array = []\n",
    "\n",
    "    #iter over every row \n",
    "    for _idx, row in dataframe.iterrows():\n",
    "        data_str = row[config_visual_stimulus_variable]\n",
    "        data_str = data_str.strip()\n",
    "        coordinates_str = data_str.split(\" \")\n",
    "        coordinates = []\n",
    "       \n",
    "        # iter over every coordinate pair x-y\n",
    "        for coordinate_str in coordinates_str:\n",
    "            try:\n",
    "                coordinate = coordinate_str.split(\"-\")\n",
    "                coordinate = (int(coordinate[0]), int(coordinate[1]))\n",
    "                coordinates.append(coordinate)\n",
    "            except:\n",
    "                print(coordinate_str)\n",
    "            \n",
    "            \n",
    "        visual_stimulus_array.append(coordinates)\n",
    "        \n",
    "    visual_stimulus_data_matrix_post_false.append(visual_stimulus_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Helper Functions</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(image_array, folder, image_name):\n",
    "    \"\"\"\n",
    "    :brief saves an array of images to a certain location incrementing the postfix by a number\n",
    "    :param image_array:        array of images (np.ndarray)\n",
    "    :param folder:     prefix of image/ folder location\n",
    "    :param image_name: prefix for the image\n",
    "    \"\"\"\n",
    "    \n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    prefix = folder + image_name\n",
    "    \n",
    "    #TODO create folders if there are none present\n",
    "    for idx, data in enumerate(image_array):\n",
    "        data = data*255\n",
    "        data = np.uint8(data)\n",
    "        im = Image.fromarray(data)\n",
    "        im.save(prefix + str(idx) + '.png')\n",
    "    \n",
    "def is_in(value, tup):\n",
    "    return tup[0] <= value <= tup[1]\n",
    "\n",
    "def get_0_offset(number):\n",
    "    i = 0\n",
    "    number = int(number)\n",
    "    while number != 0:\n",
    "        number = int(number / 10)\n",
    "        i = i + 1\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(98, 60), (105, 106), (356, 103), (98, 64), (322, 101), (146, 138), (383, 146), (133, 181), (171, 222), (139, 251), (138, 277), (120, 357), (120, 357), (141, 315), (126, 220), (138, 188), (187, 50), (159, 173), (297, 100), (187, 187), (155, 224), (165, 187), (195, 223), (196, 75), (150, 220), (121, 254), (156, 285), (179, 319), (179, 319), (144, 305), (212, 73), (180, 291), (141, 345)]\n",
      "406 397\n"
     ]
    }
   ],
   "source": [
    "test = visual_stimulus_data_matrix_pre[0][0]\n",
    "print(test)\n",
    "\n",
    "        \n",
    "#im = rEYEker.draw_shape_heat_map(image_array_pre[0], test[0], click_setting, should_copy=True)\n",
    "max_width = image_array_pre[0].shape[1]\n",
    "max_height = image_array_pre[0].shape[0]\n",
    "\n",
    "print(max_width, max_height)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2. Create Single Heatmaps</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create heatmaps false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CommonChars' 'ContainsSubstring' 'CountVowels' 'ReverseArray'\n",
      " 'BinarySearchStrings' 'Multiples' 'CrossSum' 'Swap' 'InsertionSort'\n",
      " 'GreatestCommonDivisor']\n",
      "\tGoing to process datatable #9 with 10 datasets: \n",
      "\t\tdataset #0 (up to 3): [0;\n",
      "STIMULUS [(182, 163), (182, 207), (122, 95), (102, 17), (110, 55), (147, 34), (147, 41), (140, 70), (137, 108), (226, 91), (205, 131), (195, 159), (186, 183), (144, 188), (142, 229), (127, 251), (118, 283), (129, 291), (156, 326), (144, 359), (172, 310), (180, 290), (179, 314), (181, 280), (166, 182), (181, 74), (202, 40), (199, 67), (191, 103), (186, 151), (186, 187), (185, 201), (177, 227), (167, 252), (153, 289), (178, 314), (144, 359), (204, 106), (195, 51), (191, 75), (202, 112), (202, 101), (198, 46), (191, 69), (185, 252), (166, 309), (196, 96), (195, 59), (192, 73)]\n",
      "1;\n",
      "STIMULUS [(220, 222), (220, 222), (211, 186), (80, 51), (108, 94), (104, 64), (96, 28), (77, 5), (128, 32), (164, 332), (150, 393), (122, 227), (171, 77), (171, 44), (166, 57), (162, 85), (218, 49), (217, 76), (215, 93), (220, 114), (215, 138), (207, 157), (206, 174), (204, 212), (198, 258), (191, 217), (184, 183), (184, 223), (160, 261), (148, 282), (148, 299), (150, 276), (124, 338), (136, 302), (142, 278), (156, 147), (149, 85), (140, 106), (139, 54), (118, 321), (112, 366), (128, 250), (133, 164), (124, 139), (119, 96), (99, 195), (120, 342), (175, 122), (176, 90), (164, 67)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-b367766bbeaa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"STIMULUS\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstimulus_measurement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrEYEker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_shape_heat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_array_pre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstimulus_measurement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclick_setting\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshould_copy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mheatmap_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\master_arbeit\\modules\\rEYEkerAnalysis.py\u001b[0m in \u001b[0;36mdraw_shape_heat_map\u001b[1;34m(image, coordinates, click_settings, min_idx, max_idx, time_stamps, should_copy)\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[0mmax_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoordinates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m     \u001b[0mhmh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_shape_heat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoordinates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclick_settings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_stamps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\master_arbeit\\modules\\HeatmapHelpers.py\u001b[0m in \u001b[0;36mdraw_shape_heat_map\u001b[1;34m(image, min_idx, max_idx, coordinates, click_settings, time_stamps)\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[0mtime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_stamps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m             fill_for_rectangle(heat_values, coordinates[i][0], coordinates[i][1], click_settings, max_width, max_height,\n\u001b[0m\u001b[0;32m    412\u001b[0m                                time)\n\u001b[0;32m    413\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mclick_settings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_circle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\master_arbeit\\modules\\HeatmapHelpers.py\u001b[0m in \u001b[0;36mfill_for_rectangle\u001b[1;34m(heat_values, x, y, click_settings, max_width, max_height, time)\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[0my_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mclick_settings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimal_height\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mclick_settings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_radius\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_height\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     fill_rectangle_helper(x_min, x_max, y_min, y_max, minimal_x_rect, maximal_x_rect, minimal_y_rect, maximal_y_rect,\n\u001b[0m\u001b[0;32m    155\u001b[0m                           \u001b[0mclick_settings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimal_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclick_settings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimal_height\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclick_settings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_radius\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m                           x, y, heat_values, time, max_width)\n",
      "\u001b[1;32m~\\Documents\\GitHub\\master_arbeit\\modules\\HeatmapHelpers.py\u001b[0m in \u001b[0;36mfill_rectangle_helper\u001b[1;34m(x_min, x_max, y_min, y_max, minimal_x_rect, maximal_x_rect, minimal_y_rect, maximal_y_rect, minimal_width, minimal_height, grad_radius, x, y, heat_values, time, max_width)\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                 \u001b[0my_distance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m                 \u001b[0mx_distance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m                 \u001b[0mx_distance_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_distance\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mminimal_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "heatmap_matrix_pre_false = []\n",
    "print(algo_name_array_pre)\n",
    "print(\"\\tGoing to process datatable #\" + str(idx) + \" with \" + str(len(visual_stimulus_data_matrix_pre_false)) + \" datasets: \")\n",
    "\n",
    "# iterate over all the datasets\n",
    "for dataset_idx, stimulus_dataset in enumerate(visual_stimulus_data_matrix_pre_false):\n",
    "    \n",
    "    print(\"\\t\\tdataset #\" + str(dataset_idx) + \" (up to \"+ str(len(stimulus_dataset)) + \"): [\", end='')\n",
    "    heatmap_array = []\n",
    "\n",
    "    # iterate over all the measurements of the dataset\n",
    "    for visual_idx, stimulus_measurement in enumerate(stimulus_dataset):\n",
    "        print(str(visual_idx), end=\";\")\n",
    "        print()\n",
    "        print(\"STIMULUS\", stimulus_measurement)\n",
    "        im = rEYEker.draw_shape_heat_map(image_array_pre[dataset_idx], stimulus_measurement, click_setting, should_copy=True)\n",
    "        heatmap_array.append(im)\n",
    "   \n",
    "    print(\"]\")\n",
    "    heatmap_matrix_pre_false.append(heatmap_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGoing to process datatable #9 with 10 datasets: \n",
      "\t\tdataset #0 (up to 3): [0;1;2;]\n",
      "\t\tdataset #1 (up to 0): []\n",
      "\t\tdataset #2 (up to 2): [0;1;]\n",
      "\t\tdataset #3 (up to 2): [0;1;]\n",
      "\t\tdataset #4 (up to 6): [0;1;2;3;4;5;]\n",
      "\t\tdataset #5 (up to 12): [0;1;2;3;4;5;6;7;8;9;10;11;]\n",
      "\t\tdataset #6 (up to 2): [0;1;]\n",
      "\t\tdataset #7 (up to 11): [0;1;2;3;4;5;6;7;8;9;10;]\n",
      "\t\tdataset #8 (up to 0): []\n",
      "\t\tdataset #9 (up to 3): [0;1;2;]\n"
     ]
    }
   ],
   "source": [
    "heatmap_matrix_post_false = []\n",
    "print(\"\\tGoing to process datatable #\" + str(idx) + \" with \" + str(len(visual_stimulus_data_matrix_post_false)) + \" datasets: \")\n",
    "\n",
    "# iterate over all the datasets\n",
    "for dataset_idx, stimulus_dataset in enumerate(visual_stimulus_data_matrix_post_false):\n",
    "    \n",
    "    print(\"\\t\\tdataset #\" + str(dataset_idx) + \" (up to \"+ str(len(stimulus_dataset)) + \"): [\", end='')\n",
    "    heatmap_array = []\n",
    "\n",
    "    # iterate over all the measurements of the dataset\n",
    "    for visual_idx, stimulus_measurement in enumerate(stimulus_dataset):\n",
    "        print(str(visual_idx), end=\";\")\n",
    "        \n",
    "        im = rEYEker.draw_shape_heat_map(image_array_pre[dataset_idx], stimulus_measurement, click_setting, should_copy=True)\n",
    "        heatmap_array.append(im)\n",
    "   \n",
    "    print(\"]\")\n",
    "    heatmap_matrix_post_false.append(heatmap_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create heatmaps correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGoing to process datatable #9 with 10 datasets: \n",
      "\t\tdataset #0 (up to 18): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;]\n",
      "\t\tdataset #1 (up to 18): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;]\n",
      "\t\tdataset #2 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #3 (up to 17): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;]\n",
      "\t\tdataset #4 (up to 15): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;]\n",
      "\t\tdataset #5 (up to 11): [0;1;2;3;4;5;6;7;8;9;10;]\n",
      "\t\tdataset #6 (up to 19): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;]\n",
      "\t\tdataset #7 (up to 19): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;]\n",
      "\t\tdataset #8 (up to 19): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;]\n",
      "\t\tdataset #9 (up to 19): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;]\n"
     ]
    }
   ],
   "source": [
    "heatmap_matrix_pre_correct = []\n",
    "print(\"\\tGoing to process datatable #\" + str(idx) + \" with \" + str(len(visual_stimulus_data_matrix_pre_correct)) + \" datasets: \")\n",
    "\n",
    "# iterate over all the datasets\n",
    "for dataset_idx, stimulus_dataset in enumerate(visual_stimulus_data_matrix_pre_correct):\n",
    "    \n",
    "    print(\"\\t\\tdataset #\" + str(dataset_idx) + \" (up to \"+ str(len(stimulus_dataset)) + \"): [\", end='')\n",
    "    heatmap_array = []\n",
    "\n",
    "    # iterate over all the measurements of the dataset\n",
    "    for visual_idx, stimulus_measurement in enumerate(stimulus_dataset):\n",
    "        print(str(visual_idx), end=\";\")\n",
    "        \n",
    "        im = rEYEker.draw_shape_heat_map(image_array_pre[dataset_idx], stimulus_measurement, click_setting, should_copy=True)\n",
    "        heatmap_array.append(im)\n",
    "   \n",
    "    print(\"]\")\n",
    "    heatmap_matrix_pre_correct.append(heatmap_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGoing to process datatable #9 with 10 datasets: \n",
      "\t\tdataset #0 (up to 18): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;]\n",
      "\t\tdataset #1 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #2 (up to 19): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;]\n",
      "\t\tdataset #3 (up to 19): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;]\n",
      "\t\tdataset #4 (up to 14): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;]\n",
      "\t\tdataset #5 (up to 9): [0;1;2;3;4;5;6;7;8;]\n",
      "\t\tdataset #6 (up to 19): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;]\n",
      "\t\tdataset #7 (up to 10): [0;1;2;3;4;5;6;7;8;9;]\n",
      "\t\tdataset #8 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #9 (up to 18): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;]\n"
     ]
    }
   ],
   "source": [
    "heatmap_matrix_post_correct = []\n",
    "print(\"\\tGoing to process datatable #\" + str(idx) + \" with \" + str(len(visual_stimulus_data_matrix_post_correct)) + \" datasets: \")\n",
    "\n",
    "# iterate over all the datasets\n",
    "for dataset_idx, stimulus_dataset in enumerate(visual_stimulus_data_matrix_post_correct):\n",
    "    \n",
    "    print(\"\\t\\tdataset #\" + str(dataset_idx) + \" (up to \"+ str(len(stimulus_dataset)) + \"): [\", end='')\n",
    "    heatmap_array = []\n",
    "\n",
    "    # iterate over all the measurements of the dataset\n",
    "    for visual_idx, stimulus_measurement in enumerate(stimulus_dataset):\n",
    "        print(str(visual_idx), end=\";\")\n",
    "        \n",
    "        im = rEYEker.draw_shape_heat_map(image_array_pre[dataset_idx], stimulus_measurement, click_setting, should_copy=True)\n",
    "        heatmap_array.append(im)\n",
    "   \n",
    "    print(\"]\")\n",
    "    heatmap_matrix_post_correct.append(heatmap_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGoing to process datatable #9 with 10 datasets: \n",
      "\t\tdataset #0 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #1 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #2 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #3 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #4 (up to 20): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;]\n",
      "\t\tdataset #5 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #6 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #7 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #8 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #9 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n"
     ]
    }
   ],
   "source": [
    "heatmap_matrix = []\n",
    "print(\"\\tGoing to process datatable #\" + str(idx) + \" with \" + str(len(visual_stimulus_data_matrix_pre)) + \" datasets: \")\n",
    "\n",
    "# iterate over all the datasets\n",
    "for dataset_idx, stimulus_dataset in enumerate(visual_stimulus_data_matrix_pre):\n",
    "    \n",
    "    print(\"\\t\\tdataset #\" + str(dataset_idx) + \" (up to \"+ str(len(stimulus_dataset)) + \"): [\", end='')\n",
    "    heatmap_array = []\n",
    "\n",
    "    # iterate over all the measurements of the dataset\n",
    "    for visual_idx, stimulus_measurement in enumerate(stimulus_dataset):\n",
    "        print(str(visual_idx), end=\";\")\n",
    "        \n",
    "        im = rEYEker.draw_shape_heat_map(image_array_pre[dataset_idx], stimulus_measurement, click_setting, should_copy=True)\n",
    "        heatmap_array.append(im)\n",
    "   \n",
    "    print(\"]\")\n",
    "    heatmap_matrix.append(heatmap_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGoing to process datatable #9 with 10 datasets: \n",
      "\t\tdataset #0 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #1 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #2 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #3 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #4 (up to 20): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;]\n",
      "\t\tdataset #5 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #6 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #7 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #8 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #9 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n"
     ]
    }
   ],
   "source": [
    "heatmap_matrix_post = []\n",
    "print(\"\\tGoing to process datatable #\" + str(idx) + \" with \" + str(len(visual_stimulus_data_matrix_post)) + \" datasets: \")\n",
    "\n",
    "\n",
    "\n",
    "#iterate over all the datasets\n",
    "for dataset_idx, stimulus_dataset in enumerate(visual_stimulus_data_matrix_post):\n",
    "    \n",
    "    print(\"\\t\\tdataset #\" + str(dataset_idx) + \" (up to \"+ str(len(stimulus_dataset)) + \"): [\", end='')\n",
    "    heatmap_array_post = []\n",
    "    \n",
    "    # iterate over all the measurements of the dataset\n",
    "    for visual_idx, stimulus_measurement in enumerate(stimulus_dataset):\n",
    "        \n",
    "        print(str(visual_idx), end=\";\")\n",
    "       \n",
    "        im = rEYEker.draw_shape_heat_map(image_array_post[dataset_idx], stimulus_measurement, click_setting, should_copy=True)\n",
    "     \n",
    "        heatmap_array_post.append(im)\n",
    "   \n",
    "    print(\"]\")\n",
    "    heatmap_matrix_post.append(heatmap_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "save Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to:./results/heatmaps/pretest/CommonChars/\n",
      "Writing to:./results/heatmaps/pretest/ContainsSubstring/\n",
      "Writing to:./results/heatmaps/pretest/CountVowels/\n",
      "Writing to:./results/heatmaps/pretest/ReverseArray/\n",
      "Writing to:./results/heatmaps/pretest/BinarySearchStrings/\n",
      "Writing to:./results/heatmaps/pretest/Multiples/\n",
      "Writing to:./results/heatmaps/pretest/CrossSum/\n",
      "Writing to:./results/heatmaps/pretest/Swap/\n",
      "Writing to:./results/heatmaps/pretest/InsertionSort/\n",
      "Writing to:./results/heatmaps/pretest/GreatestCommonDivisor/\n"
     ]
    }
   ],
   "source": [
    "for idx, heatmap_array in enumerate(heatmap_matrix):\n",
    "    path = \"./results/heatmaps/pretest/\" + str(algo_name_array_pre[idx]) + \"/\"\n",
    "    print(\"Writing to:\" + path)\n",
    "    save_images(heatmap_array, path, algo_name_array_pre[idx] + \"_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to:./results/heatmaps/pretest/false/CommonChars/\n",
      "Writing to:./results/heatmaps/pretest/false/ContainsSubstring/\n",
      "Writing to:./results/heatmaps/pretest/false/CountVowels/\n",
      "Writing to:./results/heatmaps/pretest/false/ReverseArray/\n",
      "Writing to:./results/heatmaps/pretest/false/BinarySearchStrings/\n",
      "Writing to:./results/heatmaps/pretest/false/Multiples/\n",
      "Writing to:./results/heatmaps/pretest/false/CrossSum/\n",
      "Writing to:./results/heatmaps/pretest/false/Swap/\n",
      "Writing to:./results/heatmaps/pretest/false/InsertionSort/\n",
      "Writing to:./results/heatmaps/pretest/false/GreatestCommonDivisor/\n"
     ]
    }
   ],
   "source": [
    "for idx, heatmap_array in enumerate(heatmap_matrix_pre_false):\n",
    "    path = \"./results/heatmaps/pretest/false/\" + str(algo_name_array_pre[idx]) + \"/\"\n",
    "    print(\"Writing to:\" + path)\n",
    "    save_images(heatmap_array, path, algo_name_array_pre[idx] + \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to:./results/heatmaps/pretest/correct/CommonChars/\n",
      "Writing to:./results/heatmaps/pretest/correct/ContainsSubstring/\n",
      "Writing to:./results/heatmaps/pretest/correct/CountVowels/\n",
      "Writing to:./results/heatmaps/pretest/correct/ReverseArray/\n",
      "Writing to:./results/heatmaps/pretest/correct/BinarySearchStrings/\n",
      "Writing to:./results/heatmaps/pretest/correct/Multiples/\n",
      "Writing to:./results/heatmaps/pretest/correct/CrossSum/\n",
      "Writing to:./results/heatmaps/pretest/correct/Swap/\n",
      "Writing to:./results/heatmaps/pretest/correct/InsertionSort/\n",
      "Writing to:./results/heatmaps/pretest/correct/GreatestCommonDivisor/\n"
     ]
    }
   ],
   "source": [
    "for idx, heatmap_array in enumerate(heatmap_matrix_pre_correct):\n",
    "    path = \"./results/heatmaps/pretest/correct/\" + str(algo_name_array_pre[idx]) + \"/\"\n",
    "    print(\"Writing to:\" + path)\n",
    "    save_images(heatmap_array, path, algo_name_array_pre[idx] + \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to:./results/heatmaps/posttest/CommonChars/\n",
      "Writing to:./results/heatmaps/posttest/IsPalindrome/\n",
      "Writing to:./results/heatmaps/posttest/ReverseString/\n",
      "Writing to:./results/heatmaps/posttest/ReverseArray/\n",
      "Writing to:./results/heatmaps/posttest/BinarySearchStrings/\n",
      "Writing to:./results/heatmaps/posttest/Multiples/\n",
      "Writing to:./results/heatmaps/posttest/Power/\n",
      "Writing to:./results/heatmaps/posttest/GetMiddle/\n",
      "Writing to:./results/heatmaps/posttest/InsertionSort/\n",
      "Writing to:./results/heatmaps/posttest/SquareRoot/\n"
     ]
    }
   ],
   "source": [
    "for idx, heatmap_array in enumerate(heatmap_matrix_post):\n",
    "    path = \"./results/heatmaps/posttest/\" + str(algo_name_array_post[idx]) + \"/\"\n",
    "    print(\"Writing to:\" + path)\n",
    "    save_images(heatmap_array, path, algo_name_array_post[idx] + \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to:./results/heatmaps/posttest/false/CommonChars/\n",
      "Writing to:./results/heatmaps/posttest/false/ContainsSubstring/\n",
      "Writing to:./results/heatmaps/posttest/false/CountVowels/\n",
      "Writing to:./results/heatmaps/posttest/false/ReverseArray/\n",
      "Writing to:./results/heatmaps/posttest/false/BinarySearchStrings/\n",
      "Writing to:./results/heatmaps/posttest/false/Multiples/\n",
      "Writing to:./results/heatmaps/posttest/false/CrossSum/\n",
      "Writing to:./results/heatmaps/posttest/false/Swap/\n",
      "Writing to:./results/heatmaps/posttest/false/InsertionSort/\n",
      "Writing to:./results/heatmaps/posttest/false/GreatestCommonDivisor/\n"
     ]
    }
   ],
   "source": [
    "for idx, heatmap_array in enumerate(heatmap_matrix_post_false):\n",
    "    path = \"./results/heatmaps/posttest/false/\" + str(algo_name_array_pre[idx]) + \"/\"\n",
    "    print(\"Writing to:\" + path)\n",
    "    save_images(heatmap_array, path, algo_name_array_pre[idx] + \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to:./results/heatmaps/posttest/correct/CommonChars/\n",
      "Writing to:./results/heatmaps/posttest/correct/ContainsSubstring/\n",
      "Writing to:./results/heatmaps/posttest/correct/CountVowels/\n",
      "Writing to:./results/heatmaps/posttest/correct/ReverseArray/\n",
      "Writing to:./results/heatmaps/posttest/correct/BinarySearchStrings/\n",
      "Writing to:./results/heatmaps/posttest/correct/Multiples/\n",
      "Writing to:./results/heatmaps/posttest/correct/CrossSum/\n",
      "Writing to:./results/heatmaps/posttest/correct/Swap/\n",
      "Writing to:./results/heatmaps/posttest/correct/InsertionSort/\n",
      "Writing to:./results/heatmaps/posttest/correct/GreatestCommonDivisor/\n"
     ]
    }
   ],
   "source": [
    "for idx, heatmap_array in enumerate(heatmap_matrix_post_correct):\n",
    "    path = \"./results/heatmaps/posttest/correct/\" + str(algo_name_array_pre[idx]) + \"/\"\n",
    "    print(\"Writing to:\" + path)\n",
    "    save_images(heatmap_array, path, algo_name_array_pre[idx] + \"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3. Create Average Heatmaps</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create pretest heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0#1#2#3#4#5#6#7#8#9"
     ]
    }
   ],
   "source": [
    "heatmap_array = []\n",
    "mask_array = []\n",
    "shape_array = []\n",
    "\n",
    "# iterate over all the datasets\n",
    "for idx, stimulus_dataset in enumerate(visual_stimulus_data_matrix_pre):\n",
    "    print(\"#\" + str(idx), end=\"\")\n",
    "    image = image_array_pre[idx]\n",
    "    shape_array.append(image.shape)\n",
    "    im, mask = rEYEker.draw_average_shape_heat_map_rel(image, stimulus_dataset, click_setting, 1.0, 0.0, None, should_copy=True)\n",
    "    heatmap_array.append(im)\n",
    "    mask_array.append(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to:./results/averageHeatMaps/pretest/\n",
      "Writing to:./results/averageHeatMaps/pretest/\n",
      "Writing to:./results/averageHeatMaps/pretest/\n",
      "Writing to:./results/averageHeatMaps/pretest/\n",
      "Writing to:./results/averageHeatMaps/pretest/\n",
      "Writing to:./results/averageHeatMaps/pretest/\n",
      "Writing to:./results/averageHeatMaps/pretest/\n",
      "Writing to:./results/averageHeatMaps/pretest/\n",
      "Writing to:./results/averageHeatMaps/pretest/\n",
      "Writing to:./results/averageHeatMaps/pretest/\n"
     ]
    }
   ],
   "source": [
    "for idx, heatmap in enumerate(heatmap_array):\n",
    "    #path = \"./results/\" + str(algo_name_aray[algo_idx]) + \"/heatmaps/average_heatmap/\"\n",
    "    path = \"./results/averageHeatMaps/pretest/\"\n",
    "    print(\"Writing to:\" + path)\n",
    "    save_images([heatmap], path, algo_name_array_pre[idx] + \"-Pretest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0#1#2#3#4#5#6#7#8#9"
     ]
    }
   ],
   "source": [
    "heatmap_array = []\n",
    "mask_array = []\n",
    "shape_array = []\n",
    "\n",
    "indizes = []\n",
    "\n",
    "# iterate over all the datasets\n",
    "for idx, stimulus_dataset in enumerate(visual_stimulus_data_matrix_pre_false):        \n",
    "    print(\"#\" + str(idx), end=\"\")\n",
    "    image = image_array_pre[idx]\n",
    "    shape_array.append(image.shape)\n",
    "    if len(stimulus_dataset) == 0:\n",
    "        indizes.append(idx)\n",
    "        continue\n",
    "    im, mask = rEYEker.draw_average_shape_heat_map_rel(image, stimulus_dataset, click_setting, 1.0, 0.0, None, should_copy=True)\n",
    "    heatmap_array.append(im)\n",
    "    mask_array.append(mask)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for idx, heatmap in enumerate(heatmap_array):\n",
    "    if idx in indizes:\n",
    "        counter += 1\n",
    "    image_idx = idx + counter\n",
    "    #path = \"./results/\" + str(algo_name_aray[algo_idx]) + \"/heatmaps/average_heatmap/\"\n",
    "    path = \"./results/averageHeatMaps/pretest/false/\"\n",
    "    #print(\"Writing to:\" + path)\n",
    "    save_images([heatmap], path, algo_name_array_pre[image_idx] + \"-pretest-false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0#1#2#3#4#5#6#7#8#9"
     ]
    }
   ],
   "source": [
    "heatmap_array = []\n",
    "mask_array = []\n",
    "shape_array = []\n",
    "\n",
    "# iterate over all the datasets\n",
    "for idx, stimulus_dataset in enumerate(visual_stimulus_data_matrix_pre_correct):\n",
    "    print(\"#\" + str(idx), end=\"\")\n",
    "    image = image_array_pre[idx]\n",
    "    shape_array.append(image.shape)\n",
    "    im, mask = rEYEker.draw_average_shape_heat_map_rel(image, stimulus_dataset, click_setting, 1.0, 0.0, None, should_copy=True)\n",
    "    heatmap_array.append(im)\n",
    "    mask_array.append(mask)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to:./results/averageHeatMaps/pretest/correct/\n",
      "Writing to:./results/averageHeatMaps/pretest/correct/\n",
      "Writing to:./results/averageHeatMaps/pretest/correct/\n",
      "Writing to:./results/averageHeatMaps/pretest/correct/\n",
      "Writing to:./results/averageHeatMaps/pretest/correct/\n",
      "Writing to:./results/averageHeatMaps/pretest/correct/\n",
      "Writing to:./results/averageHeatMaps/pretest/correct/\n",
      "Writing to:./results/averageHeatMaps/pretest/correct/\n",
      "Writing to:./results/averageHeatMaps/pretest/correct/\n",
      "Writing to:./results/averageHeatMaps/pretest/correct/\n"
     ]
    }
   ],
   "source": [
    "for idx, heatmap in enumerate(heatmap_array):\n",
    "    #path = \"./results/\" + str(algo_name_aray[algo_idx]) + \"/heatmaps/average_heatmap/\"\n",
    "    path = \"./results/averageHeatMaps/pretest/correct/\"\n",
    "    print(\"Writing to:\" + path)\n",
    "    save_images([heatmap], path, algo_name_array_pre[idx] + \"-Pretest-correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save pretest heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create posttest heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0#1#2#3#4#5#6#7#8#9"
     ]
    }
   ],
   "source": [
    "heatmap_array = []\n",
    "mask_array = []\n",
    "shape_array = []\n",
    "\n",
    "# iterate over all the datasets\n",
    "for idx, stimulus_dataset in enumerate(visual_stimulus_data_matrix_post):\n",
    "    print(\"#\" + str(idx), end=\"\")\n",
    "    image = image_array_post[idx]\n",
    "    shape_array.append(image.shape)\n",
    "    im, mask = rEYEker.draw_average_shape_heat_map_rel(image, stimulus_dataset, click_setting, 1.0, 0.0, None, should_copy=True)\n",
    "    heatmap_array.append(im)\n",
    "    mask_array.append(mask)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save posttest heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./results/averageHeatMaps/posttest/\n",
      "./results/averageHeatMaps/posttest/\n",
      "./results/averageHeatMaps/posttest/\n",
      "./results/averageHeatMaps/posttest/\n",
      "./results/averageHeatMaps/posttest/\n",
      "./results/averageHeatMaps/posttest/\n",
      "./results/averageHeatMaps/posttest/\n",
      "./results/averageHeatMaps/posttest/\n",
      "./results/averageHeatMaps/posttest/\n",
      "./results/averageHeatMaps/posttest/\n"
     ]
    }
   ],
   "source": [
    "for idx, heatmap in enumerate(heatmap_array):\n",
    "    #path = \"./results/\" + str(algo_name_aray[algo_idx]) + \"/heatmaps/average_heatmap/\"\n",
    "    path = \"./results/averageHeatMaps/posttest/\"\n",
    "    print(path)\n",
    "    save_images([heatmap], path, algo_name_array_post[idx] + \"-Posttest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0#1#2#3#4#5#6#7#8#9"
     ]
    }
   ],
   "source": [
    "heatmap_array = []\n",
    "mask_array = []\n",
    "shape_array = []\n",
    "\n",
    "indizes = []\n",
    "\n",
    "# iterate over all the datasets\n",
    "for idx, stimulus_dataset in enumerate(visual_stimulus_data_matrix_post_false):        \n",
    "    print(\"#\" + str(idx), end=\"\")\n",
    "    image = image_array_post[idx]\n",
    "    shape_array.append(image.shape)\n",
    "    if len(stimulus_dataset) == 0:\n",
    "        indizes.append(idx)\n",
    "        continue\n",
    "    im, mask = rEYEker.draw_average_shape_heat_map_rel(image, stimulus_dataset, click_setting, 1.0, 0.0, None, should_copy=True)\n",
    "    heatmap_array.append(im)\n",
    "    mask_array.append(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Writing to:./results/averageHeatMaps/posttest/false/ CommonChars\n",
      "1\n",
      "Writing to:./results/averageHeatMaps/posttest/false/ ReverseString\n",
      "2\n",
      "Writing to:./results/averageHeatMaps/posttest/false/ ReverseArray\n",
      "3\n",
      "Writing to:./results/averageHeatMaps/posttest/false/ BinarySearchStrings\n",
      "4\n",
      "Writing to:./results/averageHeatMaps/posttest/false/ Multiples\n",
      "5\n",
      "Writing to:./results/averageHeatMaps/posttest/false/ Power\n",
      "6\n",
      "Writing to:./results/averageHeatMaps/posttest/false/ GetMiddle\n",
      "7\n",
      "Writing to:./results/averageHeatMaps/posttest/false/ SquareRoot\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "image_idx = 0\n",
    "\n",
    "for idx, heatmap in enumerate(heatmap_array):\n",
    "    image_idx = idx + counter\n",
    "    print(idx)\n",
    "    #CommonChars 86.36363636363636\n",
    "    #IsPalindrome 100.0\n",
    "    #ReverseString 90.9090909090909\n",
    "    #ReverseArray 90.9090909090909\n",
    "    #BinarySearchStrings 72.72727272727273\n",
    "    #Multiples 45.45454545454545\n",
    "    #Power 90.9090909090909\n",
    "    #GetMiddle 50.0\n",
    "    #InsertionSort 100.0\n",
    "    #SquareRoot 86.36363636363636\n",
    "    #print(algo_name_array_post[idx], algo_name_array_post[image_idx])\n",
    "    if image_idx in indizes:\n",
    "        counter += 1\n",
    "        image_idx += 1\n",
    "    path = \"./results/averageHeatMaps/posttest/false/\"\n",
    "    print(\"Writing to:\" + path, algo_name_array_post[image_idx])\n",
    "    save_images([heatmap], path, algo_name_array_post[image_idx] + \"-posttest-false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0#1#2#3#4#5#6#7#8#9"
     ]
    }
   ],
   "source": [
    "heatmap_array = []\n",
    "mask_array = []\n",
    "shape_array = []\n",
    "\n",
    "# iterate over all the datasets\n",
    "for idx, stimulus_dataset in enumerate(visual_stimulus_data_matrix_post_correct):        \n",
    "    print(\"#\" + str(idx), end=\"\")\n",
    "    image = image_array_post[idx]\n",
    "    shape_array.append(image.shape)\n",
    "    im, mask = rEYEker.draw_average_shape_heat_map_rel(image, stimulus_dataset, click_setting, 1.0, 0.0, None, should_copy=True)\n",
    "    heatmap_array.append(im)\n",
    "    mask_array.append(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to:./results/averageHeatMaps/posttest/correct/\n",
      "Writing to:./results/averageHeatMaps/posttest/correct/\n",
      "Writing to:./results/averageHeatMaps/posttest/correct/\n",
      "Writing to:./results/averageHeatMaps/posttest/correct/\n",
      "Writing to:./results/averageHeatMaps/posttest/correct/\n",
      "Writing to:./results/averageHeatMaps/posttest/correct/\n",
      "Writing to:./results/averageHeatMaps/posttest/correct/\n",
      "Writing to:./results/averageHeatMaps/posttest/correct/\n",
      "Writing to:./results/averageHeatMaps/posttest/correct/\n",
      "Writing to:./results/averageHeatMaps/posttest/correct/\n"
     ]
    }
   ],
   "source": [
    "for idx, heatmap in enumerate(heatmap_array):\n",
    "    #path = \"./results/\" + str(algo_name_aray[algo_idx]) + \"/heatmaps/average_heatmap/\"\n",
    "    path = \"./results/averageHeatMaps/posttest/correct/\"\n",
    "    print(\"Writing to:\" + path)\n",
    "    save_images([heatmap], path, algo_name_array_post[idx] + \"-Posttest-correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>4. Create Sequence diagramms</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create sequence diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tdataset #0 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #1 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #2 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #3 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #4 (up to 20): [0;1;2;3;4;5;6;7;W.I.P.:to many clicks for dataset 4 datset 7\n",
      "8;W.I.P.:to many clicks for dataset 4 datset 8\n",
      "9;10;11;12;13;14;15;16;17;18;19;]\n",
      "\t\tdataset #5 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #6 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #7 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #8 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #9 (up to 21): [0;1;2;3;4;5;6;7;8;W.I.P.:to many clicks for dataset 9 datset 8\n",
      "9;10;11;12;13;14;15;16;17;18;19;20;]\n"
     ]
    }
   ],
   "source": [
    "sequence_diagrams_matrix = []\n",
    "    \n",
    "# iterate over all the datasets\n",
    "for dataset_idx, stimulus_dataset in enumerate(visual_stimulus_data_matrix_pre):\n",
    "    sequence_diagram_array = []\n",
    "    print(\"\\t\\tdataset #\" + str(dataset_idx) + \" (up to \"+ str(len(stimulus_dataset)) + \"): [\", end='')\n",
    "\n",
    "    # iterate over all the measurements of the dataset\n",
    "    for visual_idx, stimulus_measurement in enumerate(stimulus_dataset):\n",
    "        print(str(visual_idx), end=\";\")\n",
    "        im = image_array_pre[dataset_idx]\n",
    "        try:\n",
    "            im = rEYEker.draw_vertical_line_diagram(im, stimulus_measurement, should_copy=True)\n",
    "            sequence_diagram_array.append(im)\n",
    "            \n",
    "        except:\n",
    "            #TODO\n",
    "            sequence_diagram_array.append(im.copy())\n",
    "            print(\"W.I.P.:\", end='')\n",
    "            print(\"to many clicks for dataset \" + str(dataset_idx) + \" datset \" + str(visual_idx))\n",
    "            \n",
    "    print(\"]\")\n",
    "    sequence_diagrams_matrix.append(sequence_diagram_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save sequence diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to:./results/sequence_diagrams/pretest/CommonChars/\n",
      "Writing to:./results/sequence_diagrams/pretest/ContainsSubstring/\n",
      "Writing to:./results/sequence_diagrams/pretest/CountVowels/\n",
      "Writing to:./results/sequence_diagrams/pretest/ReverseArray/\n",
      "Writing to:./results/sequence_diagrams/pretest/BinarySearchStrings/\n",
      "Writing to:./results/sequence_diagrams/pretest/Multiples/\n",
      "Writing to:./results/sequence_diagrams/pretest/CrossSum/\n",
      "Writing to:./results/sequence_diagrams/pretest/Swap/\n",
      "Writing to:./results/sequence_diagrams/pretest/InsertionSort/\n",
      "Writing to:./results/sequence_diagrams/pretest/GreatestCommonDivisor/\n"
     ]
    }
   ],
   "source": [
    "for idx, sequence_diagram_array in enumerate(sequence_diagrams_matrix):\n",
    "    path = \"./results/sequence_diagrams/pretest/\" +  str(algo_name_array_pre[idx]) + \"/\"\n",
    "    print(\"Writing to:\" + path)\n",
    "    save_images(sequence_diagram_array, path, algo_name_array_pre[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tdataset #0 (up to 21): [0;1;2;3;4;to many clicks for dataset 0 dataset 4\n",
      "5;6;7;to many clicks for dataset 0 dataset 7\n",
      "8;9;10;11;12;13;14;to many clicks for dataset 0 dataset 14\n",
      "15;16;17;18;19;to many clicks for dataset 0 dataset 19\n",
      "20;to many clicks for dataset 0 dataset 20\n",
      "]\n",
      "\t\tdataset #1 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #2 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #3 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #4 (up to 20): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;]\n",
      "\t\tdataset #5 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #6 (up to 21): [0;1;to many clicks for dataset 6 dataset 1\n",
      "2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #7 (up to 21): [0;to many clicks for dataset 7 dataset 0\n",
      "1;to many clicks for dataset 7 dataset 1\n",
      "2;to many clicks for dataset 7 dataset 2\n",
      "3;to many clicks for dataset 7 dataset 3\n",
      "4;to many clicks for dataset 7 dataset 4\n",
      "5;to many clicks for dataset 7 dataset 5\n",
      "6;to many clicks for dataset 7 dataset 6\n",
      "7;to many clicks for dataset 7 dataset 7\n",
      "8;to many clicks for dataset 7 dataset 8\n",
      "9;to many clicks for dataset 7 dataset 9\n",
      "10;to many clicks for dataset 7 dataset 10\n",
      "11;to many clicks for dataset 7 dataset 11\n",
      "12;to many clicks for dataset 7 dataset 12\n",
      "13;to many clicks for dataset 7 dataset 13\n",
      "14;to many clicks for dataset 7 dataset 14\n",
      "15;to many clicks for dataset 7 dataset 15\n",
      "16;to many clicks for dataset 7 dataset 16\n",
      "17;to many clicks for dataset 7 dataset 17\n",
      "18;to many clicks for dataset 7 dataset 18\n",
      "19;to many clicks for dataset 7 dataset 19\n",
      "20;to many clicks for dataset 7 dataset 20\n",
      "]\n",
      "\t\tdataset #8 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n",
      "\t\tdataset #9 (up to 21): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;]\n"
     ]
    }
   ],
   "source": [
    "sequence_diagrams_matrix = []\n",
    "    \n",
    "# iterate over all the datasets\n",
    "for dataset_idx, stimulus_dataset in enumerate(visual_stimulus_data_matrix_post):\n",
    "    sequence_diagram_array = []\n",
    "    print(\"\\t\\tdataset #\" + str(dataset_idx) + \" (up to \"+ str(len(stimulus_dataset)) + \"): [\", end='')\n",
    "\n",
    "    # iterate over all the measurements of the dataset\n",
    "    for visual_idx, stimulus_measurement in enumerate(stimulus_dataset):\n",
    "        print(str(visual_idx), end=\";\")\n",
    "        im = image_array_pre[dataset_idx]\n",
    "        try:\n",
    "            im = rEYEker.draw_vertical_line_diagram(im, stimulus_measurement, should_copy=True)\n",
    "            sequence_diagram_array.append(im)\n",
    "            \n",
    "        except:\n",
    "            #TODO\n",
    "            sequence_diagram_array.append(im.copy())\n",
    "            #print(\"W.I.P.:\", end='')\n",
    "            print(\"to many clicks for dataset \" + str(dataset_idx) + \" dataset \" + str(visual_idx))\n",
    "            \n",
    "    print(\"]\")\n",
    "    sequence_diagrams_matrix.append(sequence_diagram_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
