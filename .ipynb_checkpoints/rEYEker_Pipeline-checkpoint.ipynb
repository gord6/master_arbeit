{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Data Analysis for REYeker</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lib for dataframes\n",
    "import pandas as pd\n",
    "\n",
    "# lib for saving np images\n",
    "from PIL import Image\n",
    "\n",
    "# lib for plotting\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# lib for numerical computations\n",
    "import numpy as np\n",
    "\n",
    "# lib for crerating paths\n",
    "from pathlib import Path\n",
    "\n",
    "# REYeker lib\n",
    "import modules.rEYEkerAnalysis as rEYEker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Configuration</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Database configuration </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the datafile\n",
    "config_datasheet_path = r'./results/preprocessed.xlsx'\n",
    "\n",
    "# columns with visual stimulus data\n",
    "config_visual_stimulus_variable = \"ClickData\"\n",
    "\n",
    "# columns with programming style\n",
    "config_programming_style_variable = \"ProgrammingStyle\"\n",
    "\n",
    "# columns with comprehension style\n",
    "config_comprehension_variable = \"Comprehension\"\n",
    "\n",
    "# columns with names of the algo\n",
    "config_algo_name_variable = \"Algorithm\"\n",
    "\n",
    "# columns with correctness value\n",
    "config_corectness_variable = \"Correctness\"\n",
    "\n",
    "# columns with time data of visual stimulus\n",
    "config_time_variable_array = []\n",
    "\n",
    "# columns with the given answers of the studen\n",
    "config_flag_variable = \"Flag\"\n",
    "\n",
    "# colums of response time\n",
    "config_response_time_variable = \"ResponseTime\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Configuration for REYEker data </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file for loading rEYEker settings\n",
    "config_reyeker_settings_path = \"data/used.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Import the preprocessed dataframe</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>ProgrammingStyle</th>\n",
       "      <th>Comprehension</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Flag</th>\n",
       "      <th>Correctness</th>\n",
       "      <th>ClickData</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>638</td>\n",
       "      <td>R</td>\n",
       "      <td>BU</td>\n",
       "      <td>BinarySearch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>136-143 182-47 475-78 284-96 190-147 437-143 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>712</td>\n",
       "      <td>R</td>\n",
       "      <td>BU</td>\n",
       "      <td>BinarySearch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>149-33 282-94 218-194 513-176 224-204 487-235 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>750</td>\n",
       "      <td>R</td>\n",
       "      <td>BU</td>\n",
       "      <td>BinarySearch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>464-76 144-124 406-176 534-235 307-273 541-370...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>784</td>\n",
       "      <td>R</td>\n",
       "      <td>BU</td>\n",
       "      <td>BinarySearch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>176-32 413-60 216-110 426-77 209-116 286-166 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>841</td>\n",
       "      <td>R</td>\n",
       "      <td>BU</td>\n",
       "      <td>BinarySearch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>195-40 450-92 201-104 196-137 535-171 208-217 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>875</td>\n",
       "      <td>I</td>\n",
       "      <td>TD</td>\n",
       "      <td>ReverseString</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>298-61 329-137 313-288 358-408 629-400 264-439...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>876</td>\n",
       "      <td>I</td>\n",
       "      <td>TD</td>\n",
       "      <td>ReverseString</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>162-49 260-83 317-36 187-10 392-20 50-55 178-7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>900</td>\n",
       "      <td>I</td>\n",
       "      <td>TD</td>\n",
       "      <td>ReverseString</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>86-51 381-36 146-150 349-149 165-154 138-536 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>939</td>\n",
       "      <td>I</td>\n",
       "      <td>TD</td>\n",
       "      <td>ReverseString</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>200-3 322-30 318-31 372-81 127-127 284-134 348...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>945</td>\n",
       "      <td>I</td>\n",
       "      <td>TD</td>\n",
       "      <td>ReverseString</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>188-80 267-150 274-470 268-414 270-262 270-302...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>389 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject ProgrammingStyle Comprehension      Algorithm  Flag  Correctness  \\\n",
       "0        638                R            BU   BinarySearch   NaN         True   \n",
       "1        712                R            BU   BinarySearch   NaN         True   \n",
       "2        750                R            BU   BinarySearch   NaN         True   \n",
       "3        784                R            BU   BinarySearch   NaN         True   \n",
       "5        841                R            BU   BinarySearch   NaN         True   \n",
       "..       ...              ...           ...            ...   ...          ...   \n",
       "644      875                I            TD  ReverseString   NaN         True   \n",
       "645      876                I            TD  ReverseString   NaN         True   \n",
       "647      900                I            TD  ReverseString   NaN         True   \n",
       "648      939                I            TD  ReverseString   NaN         True   \n",
       "649      945                I            TD  ReverseString   NaN         True   \n",
       "\n",
       "                                             ClickData  \n",
       "0    136-143 182-47 475-78 284-96 190-147 437-143 1...  \n",
       "1    149-33 282-94 218-194 513-176 224-204 487-235 ...  \n",
       "2    464-76 144-124 406-176 534-235 307-273 541-370...  \n",
       "3    176-32 413-60 216-110 426-77 209-116 286-166 5...  \n",
       "5    195-40 450-92 201-104 196-137 535-171 208-217 ...  \n",
       "..                                                 ...  \n",
       "644  298-61 329-137 313-288 358-408 629-400 264-439...  \n",
       "645  162-49 260-83 317-36 187-10 392-20 50-55 178-7...  \n",
       "647  86-51 381-36 146-150 349-149 165-154 138-536 4...  \n",
       "648  200-3 322-30 318-31 372-81 127-127 284-134 348...  \n",
       "649  188-80 267-150 274-470 268-414 270-262 270-302...  \n",
       "\n",
       "[389 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "needed_columns = [\"Subject\",\n",
    "                  config_programming_style_variable, \n",
    "                  config_comprehension_variable, \n",
    "                  config_algo_name_variable,\n",
    "                  config_flag_variable,\n",
    "                  config_corectness_variable,\n",
    "                  config_visual_stimulus_variable]\n",
    "\n",
    "raw = pd.read_excel(config_datasheet_path)\n",
    "df = pd.DataFrame(raw, columns=needed_columns)\n",
    "df = df.loc[df[\"Correctness\"]==True]\n",
    "algo_name_array = [name for name in df[config_algo_name_variable].unique()]\n",
    "\n",
    "df_tensor = []\n",
    "\n",
    "for algo_name in algo_name_array:\n",
    "    algo_df = df.loc[df[config_algo_name_variable]==algo_name]\n",
    "    df_array = [algo_df.loc[(df[config_programming_style_variable]==\"R\") & (algo_df[config_comprehension_variable]==\"BU\")],\n",
    "                algo_df.loc[(df[config_programming_style_variable]==\"I\") & (algo_df[config_comprehension_variable]==\"BU\")],\n",
    "                algo_df.loc[(df[config_programming_style_variable]==\"R\") & (algo_df[config_comprehension_variable]==\"TD\")],\n",
    "                algo_df.loc[(df[config_programming_style_variable]==\"I\") & (algo_df[config_comprehension_variable]==\"TD\")],]\n",
    "    df_tensor.append(df_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for loading the images\n",
    "image_path_tensor = []\n",
    "\n",
    "for algo_name in algo_name_array:\n",
    "    image_path_array =[\n",
    "        'images/BR/BR_' + algo_name + '.png',\n",
    "        'images/BI/BI_' + algo_name + '.png',\n",
    "        'images/TR/TR_' + algo_name + '.png',\n",
    "        'images/TI/TI_' + algo_name + '.png',\n",
    "    ]\n",
    "    image_path_tensor.append(image_path_array)\n",
    "    \n",
    "# where to save to heatmaps and sequence diagrams\n",
    "config_folder_prefix_array = ['BR/','BI/', 'TR/','TI/']\n",
    "\n",
    "# used for saving the heatmaps and sequence diagrams\n",
    "config_image_prefix_tensor = []\n",
    "for algo_name in algo_name_array:\n",
    "    image_prefix_array =[\n",
    "        'BR_' + algo_name + '_',\n",
    "        'BI_' + algo_name + '_',\n",
    "        'TR_' + algo_name + '_',\n",
    "        'TI_' + algo_name + '_',\n",
    "    ]\n",
    "    config_image_prefix_tensor.append(image_prefix_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Splitting Dataframes in right and wrong answers.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tensor_right = [[df.loc[df[config_corectness_variable]==True] for df in df_array] for df_array in df_tensor]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Remove Outliers</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tensor = [[df.loc[df[config_flag_variable]!=\"outlier\"]  for df in df_array] for df_array in df_tensor_right]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Import REYeker Settings</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_data, _times, click_setting) = rEYEker.load_data_from_json(config_reyeker_settings_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Import Images Settings</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensor = []\n",
    "\n",
    "# read in every image\n",
    "for image_path_array in image_path_tensor:\n",
    "    image_array = []\n",
    "    for image_path in image_path_array:\n",
    "        img = rEYEker.load_image(image_path)\n",
    "        image_array.append(img)\n",
    "    image_tensor.append(image_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Cast Data to Valid format</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the visual stimulus measured Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_stimulus_data_tensor = []\n",
    "\n",
    "#iter over every dataframe\n",
    "for df_array in df_tensor: \n",
    "    \n",
    "    visual_stimulus_data_matrix = []\n",
    "    for idx, dataframe in enumerate(df_array):\n",
    "        visual_stimulus_array = []\n",
    "    \n",
    "        #iter over every row \n",
    "        for _idx, row in dataframe.iterrows():\n",
    "            data_str = row[config_visual_stimulus_variable]\n",
    "            data_str = data_str.strip()\n",
    "            coordinates_str = data_str.split(\" \")\n",
    "            coordinates = []\n",
    "           \n",
    "            # iter over every coordinate pair x-y\n",
    "            for coordinate_str in coordinates_str:\n",
    "                try:\n",
    "                    coordinate = coordinate_str.split(\"-\")\n",
    "                    coordinate = (int(coordinate[0]), int(coordinate[1]))\n",
    "                    coordinates.append(coordinate)\n",
    "                except:\n",
    "                    print(coordinate_str)\n",
    "                \n",
    "                \n",
    "            visual_stimulus_array.append(coordinates)\n",
    "            \n",
    "        visual_stimulus_data_matrix.append(visual_stimulus_array)\n",
    "        \n",
    "    visual_stimulus_data_tensor.append(visual_stimulus_data_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Helper Functions</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(image_array, folder, image_name):\n",
    "    \"\"\"\n",
    "    :brief saves an array of images to a certain location incrementing the postfix by a number\n",
    "    :param image_array:        array of images (np.ndarray)\n",
    "    :param folder:     prefix of image/ folder location\n",
    "    :param image_name: prefix for the image\n",
    "    \"\"\"\n",
    "    \n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    prefix = folder + image_name\n",
    "    \n",
    "    #TODO create folders if there are none present\n",
    "    for idx, data in enumerate(image_array):\n",
    "        data = data*255\n",
    "        data = np.uint8(data)\n",
    "        im = Image.fromarray(data)\n",
    "        im.save(prefix + str(idx) + '.png')\n",
    "        \n",
    "def compare_for_h0(arr_1, arr_2, alpha):\n",
    "    t, p = stats.ttest_ind(arr_1, arr_2)\n",
    "    if p > alpha:\n",
    "        return True, t, p\n",
    "    else:\n",
    "        return False, t, p\n",
    "    \n",
    "def is_in(value, tup):\n",
    "    return tup[0] <= value <= tup[1]\n",
    "\n",
    "def get_0_offset(number):\n",
    "    i = 0\n",
    "    number = int(number)\n",
    "    while number != 0:\n",
    "        number = int(number / 10)\n",
    "        i = i + 1\n",
    "    return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2. Create Single Heatmaps</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to process 8 datatables: \n",
      "\tGoing to process datatable #0 with 4 datasets: \n",
      "\t\tdataset #0 (up to 7): [0;1;2;3;4;5;6;]\n",
      "\t\tdataset #1 (up to 3): [0;1;2;]\n",
      "\t\tdataset #2 (up to 3): [0;1;2;]\n",
      "\t\tdataset #3 (up to 9): [0;1;2;3;4;5;6;7;8;]\n",
      "\tGoing to process datatable #1 with 4 datasets: \n",
      "\t\tdataset #0 (up to 13): [0;1;2;3;4;5;6;7;8;9;10;11;12;]\n",
      "\t\tdataset #1 (up to 8): [0;1;2;3;4;5;6;7;]\n",
      "\t\tdataset #2 (up to 17): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;]\n",
      "\t\tdataset #3 (up to 16): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;]\n",
      "\tGoing to process datatable #2 with 4 datasets: \n",
      "\t\tdataset #0 (up to 24): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;21;22;"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-10dee844761a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvisual_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\";\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrEYEker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_shape_heat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_tensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstimulus_measurement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclick_setting\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mshould_copy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0mheatmap_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Dokumente\\GitHub\\REyeker\\REyeker-DataAnalyses-Python\\modules\\rEYEkerAnalysis.py\u001b[0m in \u001b[0;36mdraw_shape_heat_map\u001b[1;34m(image, coordinates, click_settings, min_idx, max_idx, time_stamps, should_copy)\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[0mmax_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoordinates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m     \u001b[0mhmh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_shape_heat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoordinates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclick_settings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_stamps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Dokumente\\GitHub\\REyeker\\REyeker-DataAnalyses-Python\\modules\\HeatmapHelpers.py\u001b[0m in \u001b[0;36mdraw_shape_heat_map\u001b[1;34m(image, min_idx, max_idx, coordinates, click_settings, time_stamps)\u001b[0m\n\u001b[0;32m    419\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m             \u001b[0mtime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_stamps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m             fill_for_rectangle(heat_values, coordinates[i][0], coordinates[i][1], click_settings, max_width, max_height,\n\u001b[0m\u001b[0;32m    422\u001b[0m                                time)\n\u001b[0;32m    423\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mclick_settings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_circle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Dokumente\\GitHub\\REyeker\\REyeker-DataAnalyses-Python\\modules\\HeatmapHelpers.py\u001b[0m in \u001b[0;36mfill_for_rectangle\u001b[1;34m(heat_values, x, y, click_settings, max_width, max_height, time)\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[0my_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mclick_settings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimal_height\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mclick_settings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_radius\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_height\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     fill_rectangle_helper(x_min, x_max, y_min, y_max, minimal_x_rect, maximal_x_rect, minimal_y_rect, maximal_y_rect,\n\u001b[0m\u001b[0;32m    155\u001b[0m                           \u001b[0mclick_settings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimal_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclick_settings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimal_height\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclick_settings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_radius\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m                           x, y, heat_values, time, max_width)\n",
      "\u001b[1;32m~\\OneDrive\\Dokumente\\GitHub\\REyeker\\REyeker-DataAnalyses-Python\\modules\\HeatmapHelpers.py\u001b[0m in \u001b[0;36mfill_rectangle_helper\u001b[1;34m(x_min, x_max, y_min, y_max, minimal_x_rect, maximal_x_rect, minimal_y_rect, maximal_y_rect, minimal_width, minimal_height, grad_radius, x, y, heat_values, time, max_width)\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                 \u001b[0my_distance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m                 \u001b[0mx_distance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m                 \u001b[0mx_distance_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_distance\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mminimal_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "heatmap_tensor = []\n",
    "\n",
    "print(\"Going to process \" + str(len(visual_stimulus_data_tensor)) + \" datatables: \")\n",
    "for idx, visual_stimulus_data_matrix in enumerate(visual_stimulus_data_tensor):\n",
    "    heatmaps_matrix = [] \n",
    "    print(\"\\tGoing to process datatable #\" + str(idx) + \" with \" + str(len(visual_stimulus_data_matrix)) + \" datasets: \")\n",
    "    \n",
    "    # iterate over all the datasets\n",
    "    for dataset_idx, stimulus_dataset in enumerate(visual_stimulus_data_matrix):\n",
    "        \n",
    "        print(\"\\t\\tdataset #\" + str(dataset_idx) + \" (up to \"+ str(len(stimulus_dataset)) + \"): [\", end='')\n",
    "        heatmap_array = []\n",
    "    \n",
    "        # iterate over all the measurements of the dataset\n",
    "        for visual_idx, stimulus_measurement in enumerate(stimulus_dataset):\n",
    "            \n",
    "            print(str(visual_idx), end=\";\")\n",
    "            \n",
    "            im = rEYEker.draw_shape_heat_map(image_tensor[idx][dataset_idx], stimulus_measurement, click_setting, should_copy=True)\n",
    "            heatmap_array.append(im)\n",
    "       \n",
    "        print(\"]\")\n",
    "        heatmaps_matrix.append(heatmap_array)\n",
    "        \n",
    "    heatmap_tensor.append(heatmaps_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "save Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to:./results/BinarySearch/heatmaps/heatmaps/BR/\n",
      "Writing to:./results/BinarySearch/heatmaps/heatmaps/BI/\n",
      "Writing to:./results/BinarySearch/heatmaps/heatmaps/TR/\n",
      "Writing to:./results/BinarySearch/heatmaps/heatmaps/TI/\n",
      "Writing to:./results/BubbleSort/heatmaps/heatmaps/BR/\n",
      "Writing to:./results/BubbleSort/heatmaps/heatmaps/BI/\n",
      "Writing to:./results/BubbleSort/heatmaps/heatmaps/TR/\n",
      "Writing to:./results/BubbleSort/heatmaps/heatmaps/TI/\n",
      "Writing to:./results/Factorial/heatmaps/heatmaps/BR/\n",
      "Writing to:./results/Factorial/heatmaps/heatmaps/BI/\n",
      "Writing to:./results/Factorial/heatmaps/heatmaps/TR/\n",
      "Writing to:./results/Factorial/heatmaps/heatmaps/TI/\n",
      "Writing to:./results/Fibonacci/heatmaps/heatmaps/BR/\n",
      "Writing to:./results/Fibonacci/heatmaps/heatmaps/BI/\n",
      "Writing to:./results/Fibonacci/heatmaps/heatmaps/TR/\n",
      "Writing to:./results/Fibonacci/heatmaps/heatmaps/TI/\n",
      "Writing to:./results/IntegerBinary/heatmaps/heatmaps/BR/\n",
      "Writing to:./results/IntegerBinary/heatmaps/heatmaps/BI/\n",
      "Writing to:./results/IntegerBinary/heatmaps/heatmaps/TR/\n",
      "Writing to:./results/IntegerBinary/heatmaps/heatmaps/TI/\n",
      "Writing to:./results/MultiplyMatrix/heatmaps/heatmaps/BR/\n",
      "Writing to:./results/MultiplyMatrix/heatmaps/heatmaps/BI/\n",
      "Writing to:./results/MultiplyMatrix/heatmaps/heatmaps/TR/\n",
      "Writing to:./results/MultiplyMatrix/heatmaps/heatmaps/TI/\n",
      "Writing to:./results/PrimeFactors/heatmaps/heatmaps/BR/\n",
      "Writing to:./results/PrimeFactors/heatmaps/heatmaps/BI/\n",
      "Writing to:./results/PrimeFactors/heatmaps/heatmaps/TR/\n",
      "Writing to:./results/PrimeFactors/heatmaps/heatmaps/TI/\n",
      "Writing to:./results/ReverseString/heatmaps/heatmaps/BR/\n",
      "Writing to:./results/ReverseString/heatmaps/heatmaps/BI/\n",
      "Writing to:./results/ReverseString/heatmaps/heatmaps/TR/\n",
      "Writing to:./results/ReverseString/heatmaps/heatmaps/TI/\n"
     ]
    }
   ],
   "source": [
    "for algo_idx, heatmaps_matrix in enumerate(heatmap_tensor):\n",
    "    for idx, heatmap_array in enumerate(heatmaps_matrix):\n",
    "        path = \"./results/\" + str(algo_name_array[algo_idx]) + \"/heatmaps/heatmaps/\" +  config_folder_prefix_array[idx]\n",
    "        print(\"Writing to:\" + path)\n",
    "        save_images(heatmap_array, path, config_image_prefix_tensor[algo_idx][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3. Create Average Heatmaps</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to process 8 datatables: \n",
      "\tGoing to process datatable #0 with 4 datasets: \n",
      "\t\t#0#1#2#3\n",
      "\tGoing to process datatable #1 with 4 datasets: \n",
      "\t\t#0#1#2#3\n",
      "\tGoing to process datatable #2 with 4 datasets: \n",
      "\t\t#0#1#2#3\n",
      "\tGoing to process datatable #3 with 4 datasets: \n",
      "\t\t#0#1#2#3\n",
      "\tGoing to process datatable #4 with 4 datasets: \n",
      "\t\t#0#1#2#3\n",
      "\tGoing to process datatable #5 with 4 datasets: \n",
      "\t\t#0#1#2#3\n",
      "\tGoing to process datatable #6 with 4 datasets: \n",
      "\t\t#0#1#2#3\n",
      "\tGoing to process datatable #7 with 4 datasets: \n",
      "\t\t#0#1#2#3\n"
     ]
    }
   ],
   "source": [
    "heatmap_tensor = []\n",
    "mask_tensor = []\n",
    "shape_array = []\n",
    "\n",
    "print(\"Going to process \" + str(len(visual_stimulus_data_tensor)) + \" datatables: \")\n",
    "for algo_idx, visual_stimulus_data_matrix in enumerate(visual_stimulus_data_tensor):\n",
    "    average_heatmap_array = []\n",
    "    mask_array = []\n",
    "    print(\"\\tGoing to process datatable #\" + str(algo_idx) + \" with \" + str(len(visual_stimulus_data_matrix)) + \" datasets: \")\n",
    "    print(\"\\t\\t\", end=\"\")\n",
    "    \n",
    "    # iterate over all the datasets\n",
    "    for idx, stimulus_dataset in enumerate(visual_stimulus_data_matrix):\n",
    "        print(\"#\" + str(idx), end=\"\")\n",
    "        image = image_tensor[algo_idx][idx]\n",
    "        shape_array.append(image.shape)\n",
    "        visual_measurements = visual_stimulus_data_matrix[idx]\n",
    "        im, mask = rEYEker.draw_average_shape_heat_map_rel(image, visual_measurements, click_setting, 1.0, 0.7, None, should_copy=True)\n",
    "        average_heatmap_array.append(im)\n",
    "        mask_array.append(mask)\n",
    "        \n",
    "    print()\n",
    "        \n",
    "        \n",
    "    heatmap_tensor.append(average_heatmap_array)\n",
    "    mask_tensor.append(mask_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n",
      "Writing to:./07/\n"
     ]
    }
   ],
   "source": [
    "for algo_idx, heatmaps_matrix in enumerate(heatmap_tensor):\n",
    "    for idx, heatmap in enumerate(heatmaps_matrix):\n",
    "        #path = \"./results/\" + str(algo_name_array[algo_idx]) + \"/heatmaps/average_heatmap/\"\n",
    "        path = \"./results/averageHeatMaps/\"\n",
    "        print(\"Writing to:\" + path)\n",
    "        save_images([heatmap], path, config_image_prefix_tensor[algo_idx][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>4. Create Sequence diagramms</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create sequence diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to process 8 datatables: \n",
      "\tGoing to process datatable #3 with 4 datasets: \n",
      "\t\tdataset #0 (up to 5): [0;1;2;3;4;]\n",
      "\t\tdataset #1 (up to 2): [0;1;]\n",
      "\t\tdataset #2 (up to 3): [0;1;2;]\n",
      "\t\tdataset #3 (up to 8): [0;1;2;3;4;5;6;7;]\n",
      "\tGoing to process datatable #3 with 4 datasets: \n",
      "\t\tdataset #0 (up to 12): [0;1;2;3;4;5;6;7;8;9;10;11;]\n",
      "\t\tdataset #1 (up to 7): [0;1;2;3;4;5;6;]\n",
      "\t\tdataset #2 (up to 5): [0;1;2;3;4;]\n",
      "\t\tdataset #3 (up to 14): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;]\n",
      "\tGoing to process datatable #3 with 4 datasets: \n",
      "\t\tdataset #0 (up to 17): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;]\n",
      "\t\tdataset #1 (up to 25): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;21;22;23;24;]\n",
      "\t\tdataset #2 (up to 24): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;21;22;23;]\n",
      "\t\tdataset #3 (up to 16): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;]\n",
      "\tGoing to process datatable #3 with 4 datasets: \n",
      "\t\tdataset #0 (up to 12): [0;1;2;3;4;5;6;7;8;9;10;11;]\n",
      "\t\tdataset #1 (up to 17): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;]\n",
      "\t\tdataset #2 (up to 14): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;]\n",
      "\t\tdataset #3 (up to 20): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;]\n",
      "\tGoing to process datatable #3 with 4 datasets: \n",
      "\t\tdataset #0 (up to 6): [0;1;2;3;4;5;]\n",
      "\t\tdataset #1 (up to 6): [0;1;2;3;4;5;]\n",
      "\t\tdataset #2 (up to 11): [0;1;2;3;4;5;6;7;8;9;10;]\n",
      "\t\tdataset #3 (up to 12): [0;1;2;3;4;5;6;7;8;9;10;11;]\n",
      "\tGoing to process datatable #3 with 4 datasets: \n",
      "\t\tdataset #0 (up to 4): [0;1;2;3;]\n",
      "\t\tdataset #1 (up to 6): [0;1;2;3;4;5;]\n",
      "\t\tdataset #2 (up to 3): [0;1;2;]\n",
      "\t\tdataset #3 (up to 3): [0;1;2;]\n",
      "\tGoing to process datatable #3 with 4 datasets: \n",
      "\t\tdataset #0 (up to 3): [0;1;2;]\n",
      "\t\tdataset #1 (up to 2): [0;1;]\n",
      "\t\tdataset #2 (up to 4): [0;1;2;3;]\n",
      "\t\tdataset #3 (up to 5): [0;1;2;3;4;]\n",
      "\tGoing to process datatable #3 with 4 datasets: \n",
      "\t\tdataset #0 (up to 13): [0;1;2;3;4;5;6;7;8;9;10;11;12;]\n",
      "\t\tdataset #1 (up to 17): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;]\n",
      "\t\tdataset #2 (up to 10): [0;1;2;3;4;5;6;7;8;9;]\n",
      "\t\tdataset #3 (up to 22): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;21;]\n"
     ]
    }
   ],
   "source": [
    "sequence_diagrams_tensor = []\n",
    "\n",
    "print(\"Going to process \" + str(len(visual_stimulus_data_tensor)) + \" datatables: \")\n",
    "for algo_idx, visual_stimulus_data_matrix in enumerate(visual_stimulus_data_tensor):\n",
    "    sequence_diagrams_matrix = []\n",
    "    print(\"\\tGoing to process datatable #\" + str(idx) + \" with \" + str(len(visual_stimulus_data_matrix)) + \" datasets: \")\n",
    "    \n",
    "    # iterate over all the datasets\n",
    "    for dataset_idx, stimulus_dataset in enumerate(visual_stimulus_data_matrix):\n",
    "        sequence_diagram_array = []\n",
    "        print(\"\\t\\tdataset #\" + str(dataset_idx) + \" (up to \"+ str(len(stimulus_dataset)) + \"): [\", end='')\n",
    "    \n",
    "        # iterate over all the measurements of the dataset\n",
    "        for visual_idx, stimulus_measurement in enumerate(stimulus_dataset):\n",
    "            print(str(visual_idx), end=\";\")\n",
    "            im = image_tensor[algo_idx][dataset_idx]\n",
    "            try:\n",
    "                im = rEYEker.draw_vertical_line_diagram(im, stimulus_measurement, should_copy=True)\n",
    "                sequence_diagram_array.append(im)\n",
    "                \n",
    "            except:\n",
    "                #TODO\n",
    "                sequence_diagram_array.append(im.copy())\n",
    "                #print(\"W.I.P.:\", end='')\n",
    "                #print(\"to many clicks for dataset \" + str(dataset_idx) + \" datset \" + str(visual_idx))\n",
    "                \n",
    "        print(\"]\")\n",
    "        sequence_diagrams_matrix.append(sequence_diagram_array)\n",
    "    sequence_diagrams_tensor.append(sequence_diagrams_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save sequence diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to:./results/BinarySearch/sequence_diagrams/BR/\n",
      "Writing to:./results/BinarySearch/sequence_diagrams/BI/\n",
      "Writing to:./results/BinarySearch/sequence_diagrams/TR/\n",
      "Writing to:./results/BinarySearch/sequence_diagrams/TI/\n",
      "Writing to:./results/BubbleSort/sequence_diagrams/BR/\n",
      "Writing to:./results/BubbleSort/sequence_diagrams/BI/\n",
      "Writing to:./results/BubbleSort/sequence_diagrams/TR/\n",
      "Writing to:./results/BubbleSort/sequence_diagrams/TI/\n",
      "Writing to:./results/Factorial/sequence_diagrams/BR/\n",
      "Writing to:./results/Factorial/sequence_diagrams/BI/\n",
      "Writing to:./results/Factorial/sequence_diagrams/TR/\n",
      "Writing to:./results/Factorial/sequence_diagrams/TI/\n",
      "Writing to:./results/Fibonacci/sequence_diagrams/BR/\n",
      "Writing to:./results/Fibonacci/sequence_diagrams/BI/\n",
      "Writing to:./results/Fibonacci/sequence_diagrams/TR/\n",
      "Writing to:./results/Fibonacci/sequence_diagrams/TI/\n",
      "Writing to:./results/IntegerBinary/sequence_diagrams/BR/\n",
      "Writing to:./results/IntegerBinary/sequence_diagrams/BI/\n",
      "Writing to:./results/IntegerBinary/sequence_diagrams/TR/\n",
      "Writing to:./results/IntegerBinary/sequence_diagrams/TI/\n",
      "Writing to:./results/MultiplyMatrix/sequence_diagrams/BR/\n",
      "Writing to:./results/MultiplyMatrix/sequence_diagrams/BI/\n",
      "Writing to:./results/MultiplyMatrix/sequence_diagrams/TR/\n",
      "Writing to:./results/MultiplyMatrix/sequence_diagrams/TI/\n",
      "Writing to:./results/PrimeFactors/sequence_diagrams/BR/\n",
      "Writing to:./results/PrimeFactors/sequence_diagrams/BI/\n",
      "Writing to:./results/PrimeFactors/sequence_diagrams/TR/\n",
      "Writing to:./results/PrimeFactors/sequence_diagrams/TI/\n",
      "Writing to:./results/ReverseString/sequence_diagrams/BR/\n",
      "Writing to:./results/ReverseString/sequence_diagrams/BI/\n",
      "Writing to:./results/ReverseString/sequence_diagrams/TR/\n",
      "Writing to:./results/ReverseString/sequence_diagrams/TI/\n"
     ]
    }
   ],
   "source": [
    "for algo_idx, sequence_diagrams_matrix in enumerate(sequence_diagrams_tensor):\n",
    "    for idx, sequence_diagram_array in enumerate(sequence_diagrams_matrix):\n",
    "        path = \"./results/\" + str(algo_name_array[algo_idx]) + \"/sequence_diagrams/\" +  config_folder_prefix_array[idx]\n",
    "        print(\"Writing to:\" + path)\n",
    "        save_images(sequence_diagram_array, path, config_image_prefix_tensor[algo_idx][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AOI categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_prefix = ['BR', 'BI', 'TR', 'TI']\n",
    "aoi_cat_path_matrix = []\n",
    "\n",
    "for algo_name in algo_name_array:\n",
    "    aoi_array =[\n",
    "        'data/aoi_categorized/AOI_BR_' + algo_name + '.xlsx',\n",
    "        'data/aoi_categorized/AOI_BI_' + algo_name + '.xlsx',\n",
    "        'data/aoi_categorized/AOI_TR_' + algo_name + '.xlsx',\n",
    "        'data/aoi_categorized/AOI_TI_' + algo_name + '.xlsx',\n",
    "    ]\n",
    "    aoi_cat_path_matrix.append(aoi_array)\n",
    "    \n",
    "aoi_df_matrix = []\n",
    "for path_array in aoi_cat_path_matrix:\n",
    "    aoi_df_array = []\n",
    "    for path in path_array:\n",
    "        raw = pd.read_excel(path)\n",
    "        tmp_df = pd.DataFrame(raw)\n",
    "        aoi_df_array.append(tmp_df)\n",
    "    aoi_df_matrix.append(aoi_df_array) \n",
    "    \n",
    "def is_in(df, y):\n",
    "    for _idx, row in df.iterrows():\n",
    "        if row[\"startHeight\"] <= y <= row[\"stopHeight\"]:\n",
    "            return row[\"Name\"]\n",
    "    return \"none\"\n",
    "\n",
    "iterative = ['none', 'main', 'Iterative definition', 'Pre calculation', 'Iteration Condition', 'Iteration Step', 'Return Result']\n",
    "recursive = ['none','main', 'Recursive definition', 'Pre calculation', 'Recursive Condition', 'Recursive Step', 'Return Result']\n",
    "order = ['0', '1', '2', '3', '4', '5', '6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "mask_array = []\n",
    "for mask_2d in mask_tensor:\n",
    "    for mask_1d in mask_2d:\n",
    "        mask_array.append(mask_1d)\n",
    "        \n",
    "aoi_df_array = []\n",
    "for aoi_df_1d in aoi_df_matrix:\n",
    "    for df in aoi_df_1d:\n",
    "        aoi_df_array.append(df)\n",
    "\n",
    "algo_df = pd.DataFrame([], columns=[\"Comprehension\", \"Programming\", \"Algorithm\"])\n",
    "for algo in algo_name_array:\n",
    "    for idx, prefix in enumerate(config_prefix):\n",
    "        comprehension = \"BU\"\n",
    "        if idx >= 2:\n",
    "            comprehension = \"TD\"\n",
    "        \n",
    "        programming = \"R\"\n",
    "        if idx%2==1:\n",
    "            programming = \"I\"\n",
    "        \n",
    "        algo_df = algo_df.append(pd.DataFrame(\n",
    "            [[comprehension, programming, algo]],\n",
    "            columns=[\"Comprehension\", \"Programming\", \"Algorithm\"]))\n",
    "algo_df = algo_df.reset_index()\n",
    "algo_df = algo_df.drop(\"index\", axis=1)\n",
    "    \n",
    "additional = iterative.copy()\n",
    "for element in recursive:\n",
    "    additional.append(element)\n",
    "\n",
    "additional = list(set(additional))\n",
    "for element in additional:\n",
    "    algo_df.insert(loc=3, column=element, value=0)\n",
    "\n",
    "for idx, mask in enumerate(mask_array):\n",
    "    height = shape_array[idx][0]\n",
    "    width = shape_array[idx][1]\n",
    "    aoi_df = aoi_df_array[idx]\n",
    "    print(idx)\n",
    "    for h in range(height):\n",
    "        for w in range(width):\n",
    "            mask_idx = h*width+w\n",
    "            if mask[mask_idx] != 0:\n",
    "                name = is_in(aoi_df, h)\n",
    "                algo_df.at[idx, name] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BinarySearch', 'BU', 'R', 'main', 'Recursive Step', 'Pre calculation', 'Recursive Condition']\n",
      "['BinarySearch', 'BU', 'I', 'main']\n",
      "['BinarySearch', 'TD', 'R', 'main']\n",
      "['BinarySearch', 'TD', 'I', 'Iteration Condition', 'main', 'Pre calculation', 'Iteration Step']\n",
      "['BubbleSort', 'BU', 'R', 'main']\n",
      "['BubbleSort', 'BU', 'I', 'main']\n",
      "['BubbleSort', 'TD', 'R', 'main']\n",
      "['BubbleSort', 'TD', 'I', 'Iteration Condition', 'main', 'Iteration Step']\n",
      "['Factorial', 'BU', 'R', 'main', 'Recursive Step', 'Recursive definition']\n",
      "['Factorial', 'BU', 'I', 'Iteration Condition', 'Iterative definition', 'Pre calculation']\n",
      "['Factorial', 'TD', 'R', 'main', 'Recursive Step', 'Recursive definition']\n",
      "['Factorial', 'TD', 'I', 'Iteration Condition', 'Iterative definition', 'Pre calculation']\n",
      "['Fibonacci', 'BU', 'R', 'none', 'Recursive Step']\n",
      "['Fibonacci', 'BU', 'I', 'Iteration Condition', 'Pre calculation', 'Iteration Step']\n",
      "['Fibonacci', 'TD', 'R', 'Recursive Step']\n",
      "['Fibonacci', 'TD', 'I', 'Iteration Condition', 'Iterative definition', 'Pre calculation', 'Iteration Step']\n",
      "['IntegerBinary', 'BU', 'R', 'Recursive Step', 'Return Result']\n",
      "['IntegerBinary', 'BU', 'I', 'Iteration Condition', 'Return Result', 'Pre calculation', 'Iteration Step']\n",
      "['IntegerBinary', 'TD', 'R', 'Recursive Step', 'Return Result']\n",
      "['IntegerBinary', 'TD', 'I', 'Iteration Condition', 'Pre calculation', 'Iteration Step']\n",
      "['MultiplyMatrix', 'BU', 'R', 'main', 'none', 'Recursive Step', 'Pre calculation', 'Recursive definition']\n",
      "['MultiplyMatrix', 'BU', 'I', 'Iteration Condition', 'Iteration Step']\n",
      "['MultiplyMatrix', 'TD', 'R', 'main', 'Recursive Step', 'Pre calculation']\n",
      "['MultiplyMatrix', 'TD', 'I', 'Iteration Condition', 'main', 'Iteration Step']\n",
      "['PrimeFactors', 'BU', 'R', 'none', 'Recursive Step', 'Return Result', 'Pre calculation']\n",
      "['PrimeFactors', 'BU', 'I', 'Iteration Condition', 'Iteration Step']\n",
      "['PrimeFactors', 'TD', 'R', 'none', 'Recursive Step', 'Return Result', 'Pre calculation']\n",
      "['PrimeFactors', 'TD', 'I', 'Iteration Condition', 'main', 'Iteration Step']\n",
      "['ReverseString', 'BU', 'R', 'main', 'none', 'Recursive Step']\n",
      "['ReverseString', 'BU', 'I', 'Iteration Condition', 'Iteration Step']\n",
      "['ReverseString', 'TD', 'R', 'main', 'none', 'Recursive Step']\n",
      "['ReverseString', 'TD', 'I', 'Iteration Condition', 'Iteration Step']\n"
     ]
    }
   ],
   "source": [
    "#algo_df = algo_df.reset_index()\n",
    "pattern = []\n",
    "for idx, row in algo_df.iterrows():\n",
    "    algo_pattern = [row[\"Algorithm\"], row[\"Comprehension\"], row[\"Programming\"]]\n",
    "    for element in additional:\n",
    "        if row[element] >= 500:\n",
    "            algo_pattern.append(element)\n",
    "    pattern.append(algo_pattern)  \n",
    "    \n",
    "for data in pattern:\n",
    "    print(str(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
