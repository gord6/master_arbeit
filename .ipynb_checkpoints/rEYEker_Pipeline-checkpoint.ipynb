{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Data Analysis for REYeker</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lib for dataframes\n",
    "import pandas as pd\n",
    "\n",
    "# lib for saving np images\n",
    "from PIL import Image\n",
    "\n",
    "# lib for plotting\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# lib for numerical computations\n",
    "import numpy as np\n",
    "\n",
    "# lib for crerating paths\n",
    "from pathlib import Path\n",
    "\n",
    "# REYeker lib\n",
    "import modules.rEYEkerAnalysis as rEYEker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Configuration</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Database configuration </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the datafile\n",
    "config_datasheet_path = r'./results/data_of_all_removed.xlsx'\n",
    "\n",
    "# columns with visual stimulus data\n",
    "config_visual_stimulus_variable = \"ClickData\"\n",
    "\n",
    "# columns with names of the algo\n",
    "config_algo_name_variable = \"Algorithm\"\n",
    "\n",
    "# columns with correctness value\n",
    "config_corectness_variable = \"Correctness\"\n",
    "\n",
    "# colums of response time\n",
    "config_response_time_variable = \"ResponseTime\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Configuration for REYEker data </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file for loading rEYEker settings\n",
    "config_reyeker_settings_path = \"data/used.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Import the preprocessed dataframe</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(config_datasheet_path)\n",
    "algo_name_array = df[\"Algorithm\"].unique()\n",
    "\n",
    "df_array = []\n",
    "\n",
    "for algo_name in algo_name_array:\n",
    "    algo_df = df.loc[df[config_algo_name_variable]==algo_name]\n",
    "    df_array.append(algo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for loading the images\n",
    "image_path_array = []\n",
    "\n",
    "for algo_name in algo_name_array:\n",
    "    image_path = 'images/' + algo_name + '.png'\n",
    "\n",
    "    image_path_array.append(image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Import REYeker Settings</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_data, _times, click_setting) = rEYEker.load_data_from_json(config_reyeker_settings_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Import Images Settings</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/CommonChars.png\n",
      "images/ContainsSubstring.png\n",
      "images/CountVowels.png\n",
      "images/ReverseArray.png\n",
      "images/BinarySearchStrings.png\n",
      "images/Multiples.png\n",
      "images/CrossSum.png\n",
      "images/Swap.png\n",
      "images/InsertionSort.png\n",
      "images/GreatestCommonDivisor.png\n"
     ]
    }
   ],
   "source": [
    "image_array = []\n",
    "\n",
    "# read in every image\n",
    "for image_path in image_path_array:\n",
    "    print(image_path)\n",
    "    image = rEYEker.load_image(image_path)\n",
    "   \n",
    "    image_array.append(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Cast Data to Valid format</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the visual stimulus measured Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_stimulus_data_matrix = []\n",
    "\n",
    "for idx, dataframe in enumerate(df_array):\n",
    "    visual_stimulus_array = []\n",
    "\n",
    "    #iter over every row \n",
    "    for _idx, row in dataframe.iterrows():\n",
    "        data_str = row[config_visual_stimulus_variable]\n",
    "        data_str = data_str.strip()\n",
    "        coordinates_str = data_str.split(\" \")\n",
    "        coordinates = []\n",
    "       \n",
    "        # iter over every coordinate pair x-y\n",
    "        for coordinate_str in coordinates_str:\n",
    "            try:\n",
    "                coordinate = coordinate_str.split(\"-\")\n",
    "                coordinate = (int(coordinate[0]), int(coordinate[1]))\n",
    "                coordinates.append(coordinate)\n",
    "            except:\n",
    "                print(coordinate_str)\n",
    "            \n",
    "            \n",
    "        visual_stimulus_array.append(coordinates)\n",
    "        \n",
    "    visual_stimulus_data_matrix.append(visual_stimulus_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Helper Functions</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(image_array, folder, image_name):\n",
    "    \"\"\"\n",
    "    :brief saves an array of images to a certain location incrementing the postfix by a number\n",
    "    :param image_array:        array of images (np.ndarray)\n",
    "    :param folder:     prefix of image/ folder location\n",
    "    :param image_name: prefix for the image\n",
    "    \"\"\"\n",
    "    \n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    prefix = folder + image_name\n",
    "    \n",
    "    #TODO create folders if there are none present\n",
    "    for idx, data in enumerate(image_array):\n",
    "        data = data*255\n",
    "        data = np.uint8(data)\n",
    "        im = Image.fromarray(data)\n",
    "        im.save(prefix + str(idx) + '.png')\n",
    "    \n",
    "def is_in(value, tup):\n",
    "    return tup[0] <= value <= tup[1]\n",
    "\n",
    "def get_0_offset(number):\n",
    "    i = 0\n",
    "    number = int(number)\n",
    "    while number != 0:\n",
    "        number = int(number / 10)\n",
    "        i = i + 1\n",
    "    return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2. Create Single Heatmaps</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGoing to process datatable #9 with 10 datasets: \n",
      "\t\tdataset #0 (up to 49): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;21;22;23;24;25;26;27;28;29;30;31;32;33;34;35;36;37;38;39;40;41;42;43;44;45;46;47;48;]\n",
      "\t\tdataset #1 (up to 49): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;21;22;23;24;25;26;27;28;29;30;31;32;33;34;35;36;37;38;39;40;41;42;43;44;45;46;47;48;]\n",
      "\t\tdataset #2 (up to 49): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;21;22;23;24;25;26;27;28;29;30;31;32;33;34;35;36;37;38;39;40;41;42;43;44;45;46;47;48;]\n",
      "\t\tdataset #3 (up to 49): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;21;22;23;24;25;26;27;28;29;30;31;32;33;34;35;36;37;38;39;40;41;42;43;44;45;46;47;48;]\n",
      "\t\tdataset #4 (up to 48): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;21;22;23;24;25;26;27;28;29;30;31;32;33;34;35;36;37;38;39;40;41;42;43;44;45;46;47;]\n",
      "\t\tdataset #5 (up to 49): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;21;22;23;24;25;26;27;28;29;30;31;32;33;34;35;36;37;38;39;40;41;42;43;44;45;46;47;48;]\n",
      "\t\tdataset #6 (up to 49): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;21;22;23;24;25;26;27;28;29;30;31;32;33;34;35;36;37;38;39;40;41;42;43;44;45;46;47;48;]\n",
      "\t\tdataset #7 (up to 49): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;21;22;23;24;25;26;27;28;29;30;31;32;33;34;35;36;37;38;39;40;41;42;43;44;45;46;47;48;]\n",
      "\t\tdataset #8 (up to 49): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;21;22;23;24;25;26;27;28;29;30;31;32;33;34;35;36;37;38;39;40;41;42;43;44;45;46;47;48;]\n",
      "\t\tdataset #9 (up to 49): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;21;22;23;24;25;26;27;28;29;30;31;32;33;34;35;36;37;38;39;40;41;42;43;44;45;46;47;48;]\n"
     ]
    }
   ],
   "source": [
    "heatmap_matrix = []\n",
    "print(\"\\tGoing to process datatable #\" + str(idx) + \" with \" + str(len(visual_stimulus_data_matrix)) + \" datasets: \")\n",
    "\n",
    "# iterate over all the datasets\n",
    "for dataset_idx, stimulus_dataset in enumerate(visual_stimulus_data_matrix):\n",
    "    \n",
    "    print(\"\\t\\tdataset #\" + str(dataset_idx) + \" (up to \"+ str(len(stimulus_dataset)) + \"): [\", end='')\n",
    "    heatmap_array = []\n",
    "\n",
    "    # iterate over all the measurements of the dataset\n",
    "    for visual_idx, stimulus_measurement in enumerate(stimulus_dataset):\n",
    "        \n",
    "        print(str(visual_idx), end=\";\")\n",
    "        \n",
    "        im = rEYEker.draw_shape_heat_map(image_array[dataset_idx], stimulus_measurement, click_setting, should_copy=True)\n",
    "        heatmap_array.append(im)\n",
    "   \n",
    "    print(\"]\")\n",
    "    heatmap_matrix.append(heatmap_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "save Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to:./results/heatmaps/CommonChars/\n",
      "Writing to:./results/heatmaps/ContainsSubstring/\n",
      "Writing to:./results/heatmaps/CountVowels/\n",
      "Writing to:./results/heatmaps/ReverseArray/\n",
      "Writing to:./results/heatmaps/BinarySearchStrings/\n",
      "Writing to:./results/heatmaps/Multiples/\n",
      "Writing to:./results/heatmaps/CrossSum/\n",
      "Writing to:./results/heatmaps/Swap/\n",
      "Writing to:./results/heatmaps/InsertionSort/\n",
      "Writing to:./results/heatmaps/GreatestCommonDivisor/\n"
     ]
    }
   ],
   "source": [
    "for idx, heatmap_array in enumerate(heatmap_matrix):\n",
    "    path = \"./results/heatmaps/\" + str(algo_name_array[idx]) + \"/\"\n",
    "    print(\"Writing to:\" + path)\n",
    "    save_images(heatmap_array, path, algo_name_array[idx] + \"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3. Create Average Heatmaps</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0#1#2#3#4#5#6#7#8#9\n"
     ]
    }
   ],
   "source": [
    "heatmap_array = []\n",
    "mask_array = []\n",
    "shape_array = []\n",
    "\n",
    "# iterate over all the datasets\n",
    "for idx, stimulus_dataset in enumerate(visual_stimulus_data_matrix):\n",
    "    print(\"#\" + str(idx), end=\"\")\n",
    "    image = image_array[idx]\n",
    "    shape_array.append(image.shape)\n",
    "    im, mask = rEYEker.draw_average_shape_heat_map_rel(image, stimulus_dataset, click_setting, 1.0, 0.0, None, should_copy=True)\n",
    "    heatmap_array.append(im)\n",
    "    mask_array.append(mask)\n",
    "    \n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to:./results/averageHeatMaps/\n",
      "Writing to:./results/averageHeatMaps/\n",
      "Writing to:./results/averageHeatMaps/\n",
      "Writing to:./results/averageHeatMaps/\n",
      "Writing to:./results/averageHeatMaps/\n",
      "Writing to:./results/averageHeatMaps/\n",
      "Writing to:./results/averageHeatMaps/\n",
      "Writing to:./results/averageHeatMaps/\n",
      "Writing to:./results/averageHeatMaps/\n",
      "Writing to:./results/averageHeatMaps/\n"
     ]
    }
   ],
   "source": [
    "for idx, heatmap in enumerate(heatmap_array):\n",
    "    #path = \"./results/\" + str(algo_name_aray[algo_idx]) + \"/heatmaps/average_heatmap/\"\n",
    "    path = \"./results/averageHeatMaps/\"\n",
    "    print(\"Writing to:\" + path)\n",
    "    save_images([heatmap], path, algo_name_array[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>4. Create Sequence diagramms</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create sequence diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to process 8 datatables: \n",
      "\tGoing to process datatable #3 with 4 datasets: \n",
      "\t\tdataset #0 (up to 5): [0;1;2;3;4;]\n",
      "\t\tdataset #1 (up to 2): [0;1;]\n",
      "\t\tdataset #2 (up to 3): [0;1;2;]\n",
      "\t\tdataset #3 (up to 8): [0;1;2;3;4;5;6;7;]\n",
      "\tGoing to process datatable #3 with 4 datasets: \n",
      "\t\tdataset #0 (up to 12): [0;1;2;3;4;5;6;7;8;9;10;11;]\n",
      "\t\tdataset #1 (up to 7): [0;1;2;3;4;5;6;]\n",
      "\t\tdataset #2 (up to 5): [0;1;2;3;4;]\n",
      "\t\tdataset #3 (up to 14): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;]\n",
      "\tGoing to process datatable #3 with 4 datasets: \n",
      "\t\tdataset #0 (up to 17): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;]\n",
      "\t\tdataset #1 (up to 25): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;21;22;23;24;]\n",
      "\t\tdataset #2 (up to 24): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;21;22;23;]\n",
      "\t\tdataset #3 (up to 16): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;]\n",
      "\tGoing to process datatable #3 with 4 datasets: \n",
      "\t\tdataset #0 (up to 12): [0;1;2;3;4;5;6;7;8;9;10;11;]\n",
      "\t\tdataset #1 (up to 17): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;]\n",
      "\t\tdataset #2 (up to 14): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;]\n",
      "\t\tdataset #3 (up to 20): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;]\n",
      "\tGoing to process datatable #3 with 4 datasets: \n",
      "\t\tdataset #0 (up to 6): [0;1;2;3;4;5;]\n",
      "\t\tdataset #1 (up to 6): [0;1;2;3;4;5;]\n",
      "\t\tdataset #2 (up to 11): [0;1;2;3;4;5;6;7;8;9;10;]\n",
      "\t\tdataset #3 (up to 12): [0;1;2;3;4;5;6;7;8;9;10;11;]\n",
      "\tGoing to process datatable #3 with 4 datasets: \n",
      "\t\tdataset #0 (up to 4): [0;1;2;3;]\n",
      "\t\tdataset #1 (up to 6): [0;1;2;3;4;5;]\n",
      "\t\tdataset #2 (up to 3): [0;1;2;]\n",
      "\t\tdataset #3 (up to 3): [0;1;2;]\n",
      "\tGoing to process datatable #3 with 4 datasets: \n",
      "\t\tdataset #0 (up to 3): [0;1;2;]\n",
      "\t\tdataset #1 (up to 2): [0;1;]\n",
      "\t\tdataset #2 (up to 4): [0;1;2;3;]\n",
      "\t\tdataset #3 (up to 5): [0;1;2;3;4;]\n",
      "\tGoing to process datatable #3 with 4 datasets: \n",
      "\t\tdataset #0 (up to 13): [0;1;2;3;4;5;6;7;8;9;10;11;12;]\n",
      "\t\tdataset #1 (up to 17): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;]\n",
      "\t\tdataset #2 (up to 10): [0;1;2;3;4;5;6;7;8;9;]\n",
      "\t\tdataset #3 (up to 22): [0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;21;]\n"
     ]
    }
   ],
   "source": [
    "sequence_diagrams_tensor = []\n",
    "\n",
    "print(\"Going to process \" + str(len(visual_stimulus_data_tensor)) + \" datatables: \")\n",
    "for algo_idx, visual_stimulus_data_matrix in enumerate(visual_stimulus_data_tensor):\n",
    "    sequence_diagrams_matrix = []\n",
    "    print(\"\\tGoing to process datatable #\" + str(idx) + \" with \" + str(len(visual_stimulus_data_matrix)) + \" datasets: \")\n",
    "    \n",
    "    # iterate over all the datasets\n",
    "    for dataset_idx, stimulus_dataset in enumerate(visual_stimulus_data_matrix):\n",
    "        sequence_diagram_array = []\n",
    "        print(\"\\t\\tdataset #\" + str(dataset_idx) + \" (up to \"+ str(len(stimulus_dataset)) + \"): [\", end='')\n",
    "    \n",
    "        # iterate over all the measurements of the dataset\n",
    "        for visual_idx, stimulus_measurement in enumerate(stimulus_dataset):\n",
    "            print(str(visual_idx), end=\";\")\n",
    "            im = image_tensor[algo_idx][dataset_idx]\n",
    "            try:\n",
    "                im = rEYEker.draw_vertical_line_diagram(im, stimulus_measurement, should_copy=True)\n",
    "                sequence_diagram_array.append(im)\n",
    "                \n",
    "            except:\n",
    "                #TODO\n",
    "                sequence_diagram_array.append(im.copy())\n",
    "                #print(\"W.I.P.:\", end='')\n",
    "                #print(\"to many clicks for dataset \" + str(dataset_idx) + \" datset \" + str(visual_idx))\n",
    "                \n",
    "        print(\"]\")\n",
    "        sequence_diagrams_matrix.append(sequence_diagram_array)\n",
    "    sequence_diagrams_tensor.append(sequence_diagrams_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save sequence diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to:./results/BinarySearch/sequence_diagrams/BR/\n",
      "Writing to:./results/BinarySearch/sequence_diagrams/BI/\n",
      "Writing to:./results/BinarySearch/sequence_diagrams/TR/\n",
      "Writing to:./results/BinarySearch/sequence_diagrams/TI/\n",
      "Writing to:./results/BubbleSort/sequence_diagrams/BR/\n",
      "Writing to:./results/BubbleSort/sequence_diagrams/BI/\n",
      "Writing to:./results/BubbleSort/sequence_diagrams/TR/\n",
      "Writing to:./results/BubbleSort/sequence_diagrams/TI/\n",
      "Writing to:./results/Factorial/sequence_diagrams/BR/\n",
      "Writing to:./results/Factorial/sequence_diagrams/BI/\n",
      "Writing to:./results/Factorial/sequence_diagrams/TR/\n",
      "Writing to:./results/Factorial/sequence_diagrams/TI/\n",
      "Writing to:./results/Fibonacci/sequence_diagrams/BR/\n",
      "Writing to:./results/Fibonacci/sequence_diagrams/BI/\n",
      "Writing to:./results/Fibonacci/sequence_diagrams/TR/\n",
      "Writing to:./results/Fibonacci/sequence_diagrams/TI/\n",
      "Writing to:./results/IntegerBinary/sequence_diagrams/BR/\n",
      "Writing to:./results/IntegerBinary/sequence_diagrams/BI/\n",
      "Writing to:./results/IntegerBinary/sequence_diagrams/TR/\n",
      "Writing to:./results/IntegerBinary/sequence_diagrams/TI/\n",
      "Writing to:./results/MultiplyMatrix/sequence_diagrams/BR/\n",
      "Writing to:./results/MultiplyMatrix/sequence_diagrams/BI/\n",
      "Writing to:./results/MultiplyMatrix/sequence_diagrams/TR/\n",
      "Writing to:./results/MultiplyMatrix/sequence_diagrams/TI/\n",
      "Writing to:./results/PrimeFactors/sequence_diagrams/BR/\n",
      "Writing to:./results/PrimeFactors/sequence_diagrams/BI/\n",
      "Writing to:./results/PrimeFactors/sequence_diagrams/TR/\n",
      "Writing to:./results/PrimeFactors/sequence_diagrams/TI/\n",
      "Writing to:./results/ReverseString/sequence_diagrams/BR/\n",
      "Writing to:./results/ReverseString/sequence_diagrams/BI/\n",
      "Writing to:./results/ReverseString/sequence_diagrams/TR/\n",
      "Writing to:./results/ReverseString/sequence_diagrams/TI/\n"
     ]
    }
   ],
   "source": [
    "for algo_idx, sequence_diagrams_matrix in enumerate(sequence_diagrams_tensor):\n",
    "    for idx, sequence_diagram_array in enumerate(sequence_diagrams_matrix):\n",
    "        path = \"./results/\" + str(algo_name_array[algo_idx]) + \"/sequence_diagrams/\" +  config_folder_prefix_array[idx]\n",
    "        print(\"Writing to:\" + path)\n",
    "        save_images(sequence_diagram_array, path, config_image_prefix_tensor[algo_idx][idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
